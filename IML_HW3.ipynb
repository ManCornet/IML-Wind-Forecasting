{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8531373-cd83-40d0-bbc2-28b641c208e6",
   "metadata": {},
   "source": [
    "<img src=\"assets/background_notebook.jpg\" />\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2.5vw; color:#c6cde1; font-weight:bold;\">\n",
    "    Introduction to machine learning - Project\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<b>Introduction</b><br><br>\n",
    "The purpose of this project is to design a model to predict wind power 24h ahead in 10 zones, corresponding to 10 wind farms located in Australia.<br><br>\n",
    "<b>Authors</b><br><br> \n",
    "<i>Camille Bosch, Manon Cornet</i> and <i>Victor Mangeleer</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b7eac",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Initialization\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Initialize all the librairies needed for the project;</li>\n",
    "        <li style=\"margin-bottom:10px\">Define basic functions.</li>\n",
    "    </ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LIBRAIRIES --\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, median_absolute_error\n",
    "\n",
    "# -- Deep Learning Librairies --\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Allow notebook to plot in terminal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTION --\n",
    "#\n",
    "# Used to print a basic section title in terminal\n",
    "def section(title):\n",
    "\n",
    "    # Number of letters to determine section size\n",
    "    title_size = len(title)\n",
    "\n",
    "    # Section title boundaries\n",
    "    boundary  = \"-\"\n",
    "    for i in range(title_size + 1):\n",
    "        boundary += \"-\"\n",
    "    \n",
    "    # Printing section\n",
    "    print(boundary)\n",
    "    print(f\" {title} \")\n",
    "    print(boundary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd81e84f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Initialization | First look\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Load the orginal datasets (X and y);</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the head of the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Make an histogram of the speeds;</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the total speed vs power curve;</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the evolution of the speed.</li>\n",
    "    </ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LOADING ORIGINAL DATASETS --\n",
    "#\n",
    "# Stores the original dataset\n",
    "dataset_original_X = []\n",
    "dataset_original_Y = []\n",
    "\n",
    "# Load the original dataset\n",
    "for i in range(1, 11):\n",
    "    dataset_original_X.append(pd.read_csv(f\"data/original/X_Zone_{i}.csv\"))\n",
    "    dataset_original_Y.append(pd.read_csv(f\"data/original/Y_Zone_{i}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- HEAD OF THE DATASETS --\n",
    "section(\"WIND TURBINE 1 - X Dataset\")\n",
    "print(dataset_original_X[0].head())\n",
    "section(\"WIND TURBINE 1 - Y Dataset\")\n",
    "print(dataset_original_Y[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- HISTOGRAM OF THE SPEEDS --\n",
    "#\n",
    "# Extracting only relevant variables\n",
    "dataset_X1_relevant = dataset_original_X[0][[\"U10\", \"U100\", \"V10\", \"V100\"]]\n",
    "dataset_Y1_relevant = dataset_original_Y[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]   # /!\\ Removing test samples (y = -1) /!\\\n",
    "dataset_Y1_relevant = dataset_Y1_relevant[[\"TARGETVAR\"]]\n",
    "\n",
    "# Observing distributions\n",
    "dataset_X1_relevant.hist(bins = 240, figsize = (20, 15))\n",
    "dataset_Y1_relevant.hist(bins = 40, figsize = (16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0abd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING WIND VS POWER --\n",
    "#\n",
    "# Removing test data\n",
    "dataset_X_clean = dataset_original_X[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]\n",
    "dataset_Y_clean = dataset_original_Y[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]\n",
    "\n",
    "# Computing total wind speed\n",
    "u_wind   = dataset_X_clean[[\"U100\"]].to_numpy()\n",
    "v_wind   = dataset_X_clean[[\"V100\"]].to_numpy()\n",
    "wind_tot = np.sqrt(u_wind**2 + v_wind**2)\n",
    "\n",
    "# Retreiving power\n",
    "power = dataset_Y_clean[[\"TARGETVAR\"]].to_numpy()\n",
    "\n",
    "# To see more clearly, one sample out of 2 is removed\n",
    "for i in range(1):\n",
    "    wind_tot = wind_tot[1::2]\n",
    "    power    = power[1::2]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(wind_tot, power, s = 3)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Speed [m/s]\")\n",
    "plt.ylabel(\"Normalized Power [-]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING AUTO-CORRELATIONS --\n",
    "auto_corr_plot = plot_acf(dataset_original_X[0][\"U100\"], lags = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412dc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING SPEED EVOLUTION --\n",
    "#\n",
    "# Retreiving first wind turbine\n",
    "X_observation = dataset_original_X[0]\n",
    "\n",
    "# Number of hours in a year\n",
    "year = 8760\n",
    "\n",
    "# Factor to scale down our timeline (f = 2, i.e. observing 6 months)\n",
    "scale = 1\n",
    "\n",
    "# Smoothening (number of values taken for averaging)\n",
    "smooth = 2\n",
    "\n",
    "# Speed to plot the evolution\n",
    "speeds = [\"U10\"]\n",
    "\n",
    "# ---------- Plotting ----------\n",
    "# Note: Rolling allows us to average the values which \"smooth out\" the curve for better visibility\n",
    "for s in speeds:\n",
    "    X_observation.iloc[0          : int(year/scale)         ].rolling(smooth).sum().plot(y = s, use_index = True, figsize = (20, 5))\n",
    "    X_observation.iloc[int(year) : int(year * (1 + 1/scale))].rolling(smooth).sum().plot(y = s, use_index = True, figsize = (20, 5), xlabel = \"TimeSlice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ec0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SEASONAL OBSERVATIONS --\n",
    "#\n",
    "# Observing seasonal evolution of an arbitrary speed\n",
    "X_observation = dataset_original_X[0][\"U100\"]\n",
    "\n",
    "# Coputing decomposition\n",
    "seasonal_decomp = seasonal_decompose(X_observation, model = \"additive\", period = int(len(X_observation)/12))\n",
    "\n",
    "# Showing evolutions\n",
    "print(seasonal_decomp.plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c306f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Modifying | DataLoader | Correlation matrix\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Define functions used to modify/improve (hopefully) the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Define the dataloader, i.e. a custom class used to easily apply modifications to the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Compute and observe the correlation matrix between all possible modifications.</li>\n",
    "    </ul> \n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb17e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to compute the mean and variance of a variable over some timeslices (number defined by the window size) in the dataset\n",
    "def computeMeanVariance(datasets, \n",
    "                        variables = [\"U100\", \"V100\"],\n",
    "                        window    = 24,\n",
    "                        variance  = True):\n",
    "\n",
    "    # Security\n",
    "    assert window > 1, \"Window size must be greater than 1 to compute mean and var\"\n",
    "\n",
    "    # Looping over all the datasets\n",
    "    for d in datasets:\n",
    "\n",
    "        # Looping over the variables whose mean and var must be computed\n",
    "        for v in variables:\n",
    "\n",
    "            # Retreiving data \n",
    "            data = d.loc[: , [v]].to_numpy()\n",
    "\n",
    "            # Stores mean and variance (1st and 2nd : mean = their value, var = 0 otherwise NAN problem while computation)\n",
    "            mean = [data[0][0], data[1][0]]\n",
    "            var  = [0, 0]\n",
    "\n",
    "            for i in range(2, len(data)):\n",
    "\n",
    "                # Start and end index for computation\n",
    "                index_start = i - window if i - window >= 0 else 0\n",
    "                index_end   = i - 1 if i - 1 >= 0 else 0\n",
    "\n",
    "                # Computing mean and variance (much faster using numpy variables)\n",
    "                mean.append(np.mean(data[index_start:index_end]))\n",
    "                var.append(np.var(data[index_start:index_end]))\n",
    "            \n",
    "            # Adding the new data to dataset\n",
    "            d[f\"{v}_mean\"] = mean\n",
    "            if variance:\n",
    "                d[f\"{v}_var\"] = var\n",
    "\n",
    "# Used to compute the instantenous mean and variance of a variable accross multiple datasets\n",
    "def computeZonalValue(datasets, \n",
    "                      variables = [\"U100\", \"V100\"],\n",
    "                      variance  = True):\n",
    "\n",
    "    # Security\n",
    "    assert len(datasets) > 1, \"To compute mean and var, at least 2 datasets are needed\"\n",
    "\n",
    "    # Looping over the variables whose mean and var must be computed\n",
    "    for v in variables:\n",
    "\n",
    "        # Number of samples\n",
    "        nb_samples = len(datasets[0])\n",
    "\n",
    "        # Stores all the different values in numpy matrix for efficient computation\n",
    "        data = np.zeros((nb_samples, len(datasets)))\n",
    "\n",
    "        # Retreiving all the corresponding data\n",
    "        for i, d in enumerate(datasets):\n",
    "            \n",
    "            # Squeeze is there to remove useless dimension\n",
    "            data[:, i] = np.squeeze(d.loc[: , [v]].to_numpy())\n",
    "\n",
    "        # Computing mean and variance (much faster using numpy variables)\n",
    "        mean = np.mean(data, axis = 1) # Axis = 1 to make mean over each row\n",
    "        var  = np.var(data, axis = 1)\n",
    "\n",
    "        # Adding new data to all the datasets\n",
    "        for d in datasets:\n",
    "            d[f\"{v}_mean\"] = mean\n",
    "            if variance:\n",
    "                d[f\"{v}_var\"] = var\n",
    "\n",
    "# Used to add the value taken by a given variable over the past samples\n",
    "def addPastTime(datasets,\n",
    "                variables = [\"U100\", \"V100\"],\n",
    "                window    = 3):\n",
    "\n",
    "    # Security\n",
    "    assert window > 0, \"Window size must be greater than 0 to add past samples\"\n",
    "\n",
    "    # Looping over the datasets\n",
    "    for d in datasets:\n",
    "\n",
    "        # Looping over the different columns\n",
    "        for i, v in enumerate(variables):\n",
    "\n",
    "            # Retrieving current data\n",
    "            data = d[[v]].to_numpy()\n",
    "\n",
    "            # Stores all the past results\n",
    "            former_data = np.zeros((len(data), window))\n",
    "\n",
    "            # Looping over the corresponding data\n",
    "            for j in range(len(data)):\n",
    "\n",
    "                # Start and end index for retreiving values\n",
    "                index_start = j - window if j - window >= 0 else 0\n",
    "                index_end   = j if j - 1 >= 0 else 0\n",
    "                \n",
    "                # Retrieve corresponding value\n",
    "                values = data[index_start:index_end]\n",
    "\n",
    "                # Fixing case where looking at starting indexes < window size\n",
    "                if len(values) != window:\n",
    "                    values = np.append(np.zeros((window - len(values), 1)), values)\n",
    "\n",
    "                # Placing the data (such that by reading left to right: t - 1, t - 2, t - 3, ...)\n",
    "                for k, val in enumerate(values):\n",
    "                        former_data[j][k] = val\n",
    "\n",
    "            # Addding past results in the dataset\n",
    "            for t in range(window):\n",
    "                d[f\"{v}_(t-{window - t})\"] = former_data[:, t]\n",
    "\n",
    "# Used to remove specific columns from the dataset\n",
    "def remove(datasets, var_removed):\n",
    "    for d in datasets:\n",
    "        for v in var_removed:\n",
    "            d.drop(v, inplace = True, axis = 1)\n",
    "\n",
    "# Used to normalize specific columns from the dataset\n",
    "def normalize(datasets,\n",
    "              norm_type = \"max_abs\",\n",
    "              data_type = \"column\",\n",
    "              variables = [\"U10\", \"V10\", \"U100\", \"V100\"]):\n",
    "\n",
    "    # Security\n",
    "    assert norm_type in [\"max_abs\", \"standard\", \"robust\"], \"Normalization type = max_abs, standard and robust\"\n",
    "    assert data_type in [\"column\", \"all\"],                 \"Data type = column, all\"\n",
    "\n",
    "    # Normalization by columns\n",
    "    if data_type == \"column\":\n",
    "\n",
    "        # Looping overall the datasets\n",
    "        for d in datasets:\n",
    "\n",
    "            # Current data\n",
    "            data = d[variables].to_numpy()\n",
    "\n",
    "            # Normalization\n",
    "            if norm_type == \"max_abs\":\n",
    "                scaled_features = MaxAbsScaler().fit_transform(data)\n",
    "            elif norm_type == \"standard\":\n",
    "                scaled_features = StandardScaler().fit_transform(data)\n",
    "            elif norm_type == \"robust\":\n",
    "                scaled_features = RobustScaler().fit_transform(data)\n",
    "\n",
    "            # Updating values\n",
    "            d[variables] = scaled_features\n",
    "\n",
    "    # Normalization on the whole dataset\n",
    "    elif data_type == \"all\":\n",
    "\n",
    "        # Concatenation of all the dataset for the sake of simplicity\n",
    "        data = pd.concat(datasets, keys=[i for i in range(len(datasets))])\n",
    "\n",
    "        # Current data\n",
    "        data_np = data[variables].to_numpy()\n",
    "\n",
    "        # Normalization\n",
    "        if norm_type == \"max_abs\":\n",
    "            scaled_features = MaxAbsScaler().fit_transform(data_np)\n",
    "        elif norm_type == \"standard\":\n",
    "            scaled_features = StandardScaler().fit_transform(data_np)\n",
    "        elif norm_type == \"robust\":\n",
    "            scaled_features = RobustScaler().fit_transform(data_np)\n",
    "\n",
    "        # Updating values\n",
    "        data[variables] = scaled_features\n",
    "\n",
    "        # Re-creation of the datasets\n",
    "        for i in range(len(datasets)):\n",
    "            datasets[i] = data.loc[i, :]\n",
    "\n",
    "# Used to retrieve the wind direction and the wind speed from meridional and zonal comp. and add them in the dataset\n",
    "def wind_comp(datasets, \n",
    "              columns      = \"both\", \n",
    "              speed_height = \"both\"):\n",
    "\n",
    "    # Security\n",
    "    assert columns in [\"wind_speed\", \"wind_direction\", \"both\"], \"Columns      = wind_speed, wind_direction or both\"\n",
    "    assert speed_height in [\"10\", \"100\", \"both\"],               \"Speed height = 10, 100 or both\"\n",
    "\n",
    "    # Find the speed speed and the wind direction\n",
    "    for d in datasets:\n",
    "\n",
    "        # Computing speed at 10 meters from th ground\n",
    "        if speed_height in [\"10\", \"both\"]:\n",
    "            w_u_10 = d[\"U10\"].to_numpy()\n",
    "            w_v_10 = d[\"V10\"].to_numpy()\n",
    "\n",
    "            if columns in [\"wind_speed\", \"both\"]:\n",
    "                d[\"WS10\"] = np.sqrt(np.square(w_u_10) + np.square(w_v_10))\n",
    "            if columns in [\"wind_direction\", \"both\"]:\n",
    "                d[\"WS10_angle\"] = np.arctan2(w_v_10, w_u_10)\n",
    "\n",
    "        # Computing speed at 100 meters from th ground\n",
    "        if speed_height in [\"100\", \"both\"]:\n",
    "            w_u_100 = d[\"U100\"].to_numpy()\n",
    "            w_v_100 = d[\"V100\"].to_numpy()\n",
    "\n",
    "            if columns in [\"wind_speed\", \"both\"]:\n",
    "                d[\"WS100\"] = np.sqrt(np.square(w_u_100) + np.square(w_v_100))\n",
    "            if columns in [\"wind_direction\", \"both\"]:\n",
    "                d[\"WS100_angle\"] = np.arctan2(w_v_100, w_u_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADER -- \n",
    "#\n",
    "class dataLoader():\n",
    "    \n",
    "    # Initialization of the loader\n",
    "    def __init__(self, datasets_X, datasets_Y):\n",
    "\n",
    "        # Stores the original, transformed and final datasets\n",
    "        self.original_datasets_X    = datasets_X\n",
    "        self.original_datasets_Y    = datasets_Y\n",
    "        self.transformed_datasets_X = datasets_X\n",
    "        self.transformed_datasets_Y = datasets_Y\n",
    "        self.final_dataset_X        = None\n",
    "        self.final_dataset_Y        = None\n",
    "\n",
    "        # Used to know if datasets have been combined or not\n",
    "        self.isCombined = None\n",
    "\n",
    "    # Used to display the head of the transformed dataset (first set)\n",
    "    def showHeadTransformed(self):\n",
    "        section(\"Dataset - X - Transformed\")\n",
    "        print(self.transformed_datasets_X[0].head())\n",
    "        section(\"Dataset - Y - Transformed\")\n",
    "        print(self.transformed_datasets_Y[0].head())\n",
    "\n",
    "    # Used to split the final dataset into a train and test set (In test set, values for y are equal to -1)\n",
    "    def splitTrainTest(self, save = False, save_dir = \"new_data\"):\n",
    "\n",
    "        # Security\n",
    "        assert self.isCombined != None, \"You must first use self.finalize\"\n",
    "\n",
    "        # Case 1 - Datasets have been combined all together\n",
    "        if self.isCombined == True:\n",
    "            X_train = self.final_dataset_X[self.final_dataset_Y['TARGETVAR'] != -1]\n",
    "            Y_train = self.final_dataset_Y[self.final_dataset_Y['TARGETVAR'] != -1]\n",
    "            X_test  = self.final_dataset_X[self.final_dataset_Y['TARGETVAR'] == -1]\n",
    "            Y_test  = self.final_dataset_Y[self.final_dataset_Y['TARGETVAR'] == -1] # Not useful, I know !\n",
    "\n",
    "        # Case 2 - Datasets are still separated\n",
    "        if self.isCombined == False:\n",
    "            \n",
    "            X_train, Y_train, X_test, Y_test = list(), list(), list(), list()\n",
    "\n",
    "            # Looping over all the small datasets\n",
    "            for x, y in zip(self.final_dataset_X, self.final_dataset_Y):\n",
    "                X_train.append(x[y['TARGETVAR'] != -1])\n",
    "                Y_train.append(y[y['TARGETVAR'] != -1])\n",
    "                X_test.append(x[y['TARGETVAR'] == -1])\n",
    "                Y_test.append(y[y['TARGETVAR'] == -1])\n",
    "\n",
    "        # Be careful with the order\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "        \n",
    "    # Used to perfom final operation on dataset (Combining everything or storing them separately)\n",
    "    def finalization(self, dataset_type = \"combined\"):\n",
    "\n",
    "        # Security\n",
    "        assert dataset_type in [\"combined\", \"separated\"], \"The final dataset can either be of type combined or separated\"\n",
    "\n",
    "        # Case 1 - Combining into one big dataset\n",
    "        if dataset_type == \"combined\":\n",
    "            self.final_dataset_X = pd.concat(self.transformed_datasets_X)\n",
    "            self.final_dataset_Y = pd.concat(self.transformed_datasets_Y)\n",
    "            self.isCombined = True\n",
    "\n",
    "        # Case 2 - Separated datasets\n",
    "        else:\n",
    "            self.final_dataset_X = self.transformed_datasets_X\n",
    "            self.final_dataset_Y = self.transformed_datasets_Y\n",
    "            self.isCombined = False\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    #                                                               PIPELINE\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, useMeanVariance   = True,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24 * 7,\n",
    "                       useZonal          = True,  var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                       usePastTime       = True,  var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON   = 3,\n",
    "                       useNormalize      = True,  var_NORM = [\"U10\", \"V10\", \"U100\", \"V100\"], norm_type = \"max_abs\", data_type = \"column\",\n",
    "                       useSpeedNorm      = True,  SpeedNorm_height = \"both\",\n",
    "                       useSpeedDirection = True,  SpeedDir_height  = \"both\",\n",
    "                       removing          = False, var_removed      = [\"U10\", \"V10\", \"U100\", \"V100\"]):\n",
    "\n",
    "        # Copying original dataset\n",
    "        dX = copy.deepcopy(self.original_datasets_X)\n",
    "        dY = copy.deepcopy(self.original_datasets_Y)\n",
    "\n",
    "        # Applying the different transformations\n",
    "        if useNormalize:\n",
    "            normalize(dX, variables = var_NORM, norm_type = norm_type, data_type = data_type)\n",
    "        if useSpeedNorm:\n",
    "            wind_comp(dX, columns = \"wind_speed\",     speed_height = SpeedNorm_height)\n",
    "        if useSpeedDirection:\n",
    "            wind_comp(dX, columns = \"wind_direction\", speed_height = SpeedDir_height)\n",
    "        if useMeanVariance:\n",
    "            computeMeanVariance(dX, variables = var_MV, window = window_MV, variance = variance_MV)\n",
    "        if useZonal:\n",
    "            computeZonalValue(dX, variables = var_ZON, variance = variance_ZON)\n",
    "        if usePastTime:\n",
    "            addPastTime(dX, variables = var_PT, window = window_ZON)\n",
    "        if removing:\n",
    "            remove(dX, variables = var_removed)\n",
    "        \n",
    "        # Updating dataset\n",
    "        self.transformed_datasets_X = dX\n",
    "        self.transformed_datasets_Y = dY\n",
    "\n",
    "        # Making sure one has to finalize again\n",
    "        self.isCombined = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- CORRELATION MATRIX -- \n",
    "#\n",
    "# Define which correlation matrix to compute\n",
    "nb_correlation = 1\n",
    "\n",
    "# Used to plot correlation matrix\n",
    "def plotCorrelationMatrix(loader, treshold = 0.3, color = \"YlGnBu\", number = 1):\n",
    "\n",
    "    # Finalization of the loader\n",
    "    loader.finalization(dataset_type = \"combined\")\n",
    "    \n",
    "    # Retreives the train and test set (in Pandas frame)\n",
    "    data_X, _, _, _ = loader.splitTrainTest()\n",
    "\n",
    "    # Plotting correlation matrix, removing low values, changing plot color\n",
    "    corr             = data_X.corr()\n",
    "    corr[np.abs(corr) < treshold] = 0\n",
    "    sns.set(rc={'figure.figsize':(25, 20)})\n",
    "    sns.heatmap(corr, cmap = color, annot = True)\n",
    "    plt.savefig(f\"graphs/correlation/correlation_matrix_{number}.png\")\n",
    "\n",
    "# Initialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Plotting\n",
    "if nb_correlation == 1:\n",
    "    loader.pipeline(norm_type = \"max_abs\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 1)\n",
    "elif nb_correlation == 2:\n",
    "    loader.pipeline(norm_type = \"standard\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 2)\n",
    "elif nb_correlation == 3:\n",
    "    loader.pipeline(norm_type = \"robust\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 3)\n",
    "elif nb_correlation == 4:\n",
    "    loader.pipeline(norm_type = \"max_abs\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 4)\n",
    "elif nb_correlation == 5:\n",
    "    loader.pipeline(norm_type = \"standard\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 5)\n",
    "else:\n",
    "    loader.pipeline(norm_type = \"robust\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53e15ed",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Generation\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to generate and store all the different datasets that will be tested by the different methods:\n",
    "    <ol>\n",
    "        <li style=\"margin-bottom:10px\">MeanVariance : window = 3, window = 12, window = 24</li>\n",
    "        <li style=\"margin-bottom:10px\">ZonalMean</li>\n",
    "        <li style=\"margin-bottom:10px\">PastTime     : window = 1, window = 2,  window = 3</li>\n",
    "        <li style=\"margin-bottom:10px\">SpeedNorm</li>\n",
    "        <li style=\"margin-bottom:10px\">SpeedDir</li>\n",
    "    </ol> \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53870b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which datasets will be compared to one another\n",
    "dataset_choice = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Define the type of dataset\n",
    "dt = \"separated\"\n",
    "\n",
    "# If dt = \"separated\" zone_id in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \n",
    "zone_id = 1 if dt == \"separated\" else 0\n",
    "\n",
    "# Normalization parameters\n",
    "norm_parameters = [\"standard\", \"all\"]\n",
    "\n",
    "# Define the different window tested by the MeanVariance\n",
    "window_MV = [3, 12, 24]\n",
    "\n",
    "# Define the different window tested by the PastTime\n",
    "window_PT = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ea381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TEMPLATE --\n",
    "\"\"\"\n",
    "loader.pipeline(useMeanVariance    = True,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24 * 7,\n",
    "                useZonal           = True,  var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                usePastTime        = True,  var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON   = 3,\n",
    "                useNormalize       = True,  var_NORM = [\"U10\", \"V10\", \"U100\", \"V100\"], norm_type = \"max_abs\", data_type = \"column\",\n",
    "                useSpeedNorm       = True,  SpeedNorm_height = \"both\",\n",
    "                useSpeedDirection  = True,  SpeedDir_height  = \"both\",\n",
    "                removing           = False, var_removed      = [\"U10\", \"V10\", \"U100\", \"V100\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE DATASETS --\n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X, datasets_X_submit, datasets_Y, datasets_Y_submit = list(), list(), list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Retrieving the index of the zone considered\n",
    "index_zone = zone_id - 1\n",
    "\n",
    "# 0 - Originals\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = False,\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "\n",
    "\n",
    "loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "# 1 - MeanVariance\n",
    "if 1 in dataset_choice:\n",
    "    for w in window_MV:\n",
    "        loader.pipeline(useMeanVariance    = True,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = w,\n",
    "                        useZonal           = False,\n",
    "                        usePastTime        = False, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 1,\n",
    "                        useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                        useSpeedNorm       = False, SpeedNorm_height = \"both\",\n",
    "                        useSpeedDirection  = False,\n",
    "                        removing           = False)\n",
    "\n",
    "\n",
    "        loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "        X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "        datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "        datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "        datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "        datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "# 2 - ZonalMean\n",
    "if 2 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 12,\n",
    "                    useZonal           = True, var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                    usePastTime        = False, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 1,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = False, SpeedNorm_height = \"both\",\n",
    "                    useSpeedDirection  = False,\n",
    "                    removing           = False)\n",
    "\n",
    "    loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "\n",
    "# 3 - PastTime\n",
    "if 3 in dataset_choice:\n",
    "    for w in window_PT:\n",
    "        loader.pipeline(useMeanVariance    = False,  var_MV   = [\"WS10\", \"WS100\"], variance_MV  = True, window_MV = 3,\n",
    "                        useZonal           = False,\n",
    "                        usePastTime        = True, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = w,\n",
    "                        useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                        useSpeedNorm       = False, SpeedNorm_height = \"both\",\n",
    "                        useSpeedDirection  = False,\n",
    "                        removing           = False)\n",
    "\n",
    "        loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "        X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "        datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "        datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "        datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "        datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "\n",
    "# 4 - SpeedNorm\n",
    "if 4 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 12,\n",
    "                    useZonal           = False,\n",
    "                    usePastTime        = False, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 1,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = True, SpeedNorm_height = \"both\",\n",
    "                    useSpeedDirection  = False,\n",
    "                    removing           = False)\n",
    "\n",
    "    loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "\n",
    "# 5 - SpeedDir\n",
    "if 5 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 12,\n",
    "                    useZonal           = False,\n",
    "                    usePastTime        = False, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 1,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = False,\n",
    "                    useSpeedDirection  = True, SpeedDir_height  = \"both\",\n",
    "                    removing           = False)\n",
    "    \n",
    "    loader.finalization(dataset_type = \"separated\" if dt == \"separated\" else \"combined\")\n",
    "\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    datasets_X.append(X[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_Y.append(Y[index_zone] if dt == \"separated\" else X)\n",
    "    datasets_X_submit.append(submit_X[index_zone if dt == \"separated\" else X]) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else X)\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(\"Generating : Done\")\n",
    "print(f\"Number of generated datasets: {len(datasets_X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a06df83",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model - Pre-Classifier\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Trained a model to pre-classify the data (wether or not, power is created with wind conditions);</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe a custom class \"ModelEnsemble\" which allow to create a model resulting from the combination of the pre-classifier and a trained model.</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ENSEMBLE MODEL --\n",
    "#\n",
    "# The goal of this class is to create our own predict function which is composed of 2 main steps:\n",
    "# - The pre-classifier's determines whether or not the wind is sufficiently high to have a power creation\n",
    "# - The model which predicts the power creation\n",
    "class ModelEnsemble():\n",
    "\n",
    "    # Initialization of the ensemble model\n",
    "    def __init__(self, model_prec_classifier, model_trained):\n",
    "        self.pre_classifier = model_prec_classifier\n",
    "        self.trained        = model_trained \n",
    "    \n",
    "    # Used to compute predictions\n",
    "    def predict(self, x, predict_treshold = 0.95):\n",
    "\n",
    "        # 1 - Determining if there is power or not \n",
    "        PC_results  = self.pre_classifier.predict_proba(x)\n",
    "\n",
    "        # 2 - Power predictions\n",
    "        MOD_results = self.trained.predict(x)\n",
    "\n",
    "        # 3 - Replacing predictions with pre-classifier results \n",
    "        for i, r in enumerate(PC_results):\n",
    "            MOD_results[i] = 0 if r[0] > predict_treshold else MOD_results[i]\n",
    "\n",
    "        return MOD_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11846a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PRE-CLASSIFIER'S DATASET --\n",
    "# \n",
    "# Creation of the special dataset for training the pre-classifier\n",
    "dataset_X_preclassifier = copy.deepcopy(datasets_X[0])\n",
    "dataset_Y_preclassifier = copy.deepcopy(datasets_Y[0])\n",
    "\n",
    "# Transforming into binary classification problem (0 = no power, 1 = power to predict)\n",
    "dataset_Y_preclassifier[dataset_Y_preclassifier[\"TARGETVAR\"] != 0] = 1\n",
    "dataset_X_preclassifier                                            = dataset_X_preclassifier.to_numpy()\n",
    "dataset_Y_preclassifier                                            = dataset_Y_preclassifier[\"TARGETVAR\"].to_numpy()\n",
    "\n",
    "# Retreiving train and test sets\n",
    "X_PRE_train, X_PRE_test, y_PRE_train, y_PRE_test = train_test_split(dataset_X_preclassifier, dataset_Y_preclassifier, test_size = 0.3, random_state = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING OF THE PRE-CLASSIFIER -- \n",
    "#\n",
    "# Definition of the parameters that will be tested\n",
    "GS_param_dt  = {'max_depth'   : [i for i in range(7, 13)]}\n",
    "\n",
    "# Initialization of the model\n",
    "model_pre_classifier = GridSearchCV(tree.DecisionTreeClassifier(), GS_param_dt)\n",
    "\n",
    "# Finding the best parameter\n",
    "model_pre_classifier.fit(X_PRE_train, y_PRE_train)\n",
    "\n",
    "# Computing final accuracy \n",
    "accuracy_pre_classifier = model_pre_classifier.score(X_PRE_test, y_PRE_test)\n",
    "\n",
    "# Display information over terminal (1)\n",
    "section(\"Results\")\n",
    "print(f\"Pre classifier's accuracy [%] : {accuracy_pre_classifier * 100}\")\n",
    "print(model_pre_classifier.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1cb5f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model - Training | Testing | Plotting results per Zone\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Find functions to plot easily compare accuracy results of a method against each dataset.</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b153cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ERROR COMPUTATION --\n",
    "#\n",
    "# Found from : https://github.com/smazzanti\n",
    "#\n",
    "def _yield_pairs(y_true, num_rounds):\n",
    "  \"\"\"\n",
    "  Returns pairs of valid indices. Indices must belong to observations having different values.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true     : array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  num_rounds : int or string. If integer, number of random pairs of observations to return. \n",
    "               If string, 'exact', all possible pairs of observations will be returned.\n",
    "  \n",
    "  Yields:\n",
    "  -------\n",
    "  i, j: tuple of int of shape (2,). Indices referred to a pair of samples.\n",
    "  \"\"\"\n",
    "  if num_rounds == 'exact':\n",
    "    for i in range(len(y_true)):\n",
    "      for j in np.where((y_true != y_true[i]) & (np.arange(len(y_true)) > i))[0]:\n",
    "        yield i, j     \n",
    "  else:\n",
    "    for r in range(num_rounds):\n",
    "      i = np.random.choice(range(len(y_true)))\n",
    "      j = np.random.choice(np.where(y_true != y_true[i])[0])\n",
    "      yield i, j\n",
    "\n",
    "def regression_roc_auc_score(y_true, y_pred, num_rounds = 10000):\n",
    "  \"\"\"\n",
    "  Computes Regression-ROC-AUC-score.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true     : array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  y_pred     : array-like of shape (n_samples,). Target scores.\n",
    "  num_rounds : int or string. If integer, number of random pairs of observations. \n",
    "               If string, 'exact', all possible pairs of observations will be evaluated.\n",
    "  \n",
    "  Returns:\n",
    "  -------\n",
    "  rroc: float. Regression-ROC-AUC-score.\n",
    "  \"\"\"\n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "  num_pairs     = 0\n",
    "  num_same_sign = 0\n",
    "  \n",
    "  for i, j in _yield_pairs(y_true, num_rounds):\n",
    "    diff_true  = y_true[i] - y_true[j]\n",
    "    diff_score = y_pred[i] - y_pred[j]\n",
    "\n",
    "    if diff_true * diff_score > 0:\n",
    "      num_same_sign += 1\n",
    "    elif diff_score == 0:\n",
    "      num_same_sign += .5\n",
    "    num_pairs += 1\n",
    "      \n",
    "  return num_same_sign / num_pairs\n",
    "\n",
    "def computeError(n_y_true, n_y_pred):\n",
    "    \"\"\"\n",
    "    Compute the error to evaluate the performance of the model \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    n_y_true: list of np.array\n",
    "              Ground truth (correct) target values.\n",
    "\n",
    "\n",
    "    n_y_pred: list of np.array \n",
    "              Estimated target values.\n",
    "    \n",
    "   \n",
    "    \"\"\"\n",
    "    mae, rmse, mdae, r2, auc = [], [], [], [], []\n",
    "\n",
    "    for y_true, y_pred in zip(n_y_true, n_y_pred):\n",
    "        mae.append(mean_absolute_error(y_true, y_pred))\n",
    "        rmse.append(mean_squared_error(y_true, y_pred, squared = False))\n",
    "        mdae.append(median_absolute_error(y_true, y_pred))\n",
    "\n",
    "        r2.append(r2_score(y_true, y_pred))\n",
    "        auc.append(regression_roc_auc_score(y_true, y_pred, num_rounds = 1000))\n",
    "\n",
    "    return mae, rmse, mdae, r2, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to compute a model's accuracy against different datasets\n",
    "def modelTesting(datasets_X, datasets_y, model, test_size = 0.3, random_state = 69):\n",
    "    \n",
    "    # Contains mean accuracy of the model against each dataset\n",
    "    accuracy_train, accuracy_test, y_true, y_pred = list(), list(), list(), list()\n",
    "\n",
    "    # Looping over whole the different datasets\n",
    "    for X, y in zip(datasets_X, datasets_y):\n",
    "        \n",
    "        # Final conversion (Numpy and retrieving targets)\n",
    "        X = X.to_numpy()\n",
    "        y = y[[\"TARGETVAR\"]].to_numpy().ravel()\n",
    "\n",
    "        # Retrieving datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "        # Fitting the model on current split\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Prediction \n",
    "        y_pred.append(model.predict(X_test))\n",
    "        y_true.append(y_test)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy_train.append(model.score(X_train, y_train))\n",
    "        accuracy_test.append(model.score(X_test, y_test))\n",
    "\n",
    "    return accuracy_train, accuracy_test, y_pred, y_true \n",
    "\n",
    "# Used to determine the best parameter and the associated dataset\n",
    "def computeBest (parameters, acc_train, acc_test, y_pred, y_true):\n",
    "\n",
    "    # Used to store the best results\n",
    "    acc_test_best, acc_train_best = [], []\n",
    "    y_pred_best,  y_true_best     = [], []\n",
    "    param_best                    = []\n",
    "\n",
    "    # Looping over accuracies to find best results\n",
    "    for a1, a2, y1, y2 in zip(acc_train, acc_test, y_pred, y_true):\n",
    "\n",
    "        # Finding best test accuracy\n",
    "        max_value = max(a2)\n",
    "        max_index = a2.index(max_value)\n",
    "\n",
    "        # Adding results\n",
    "        acc_test_best.append(max_value)\n",
    "        acc_train_best.append(a1[max_index])\n",
    "        y_pred_best.append(y1[max_index])\n",
    "        y_true_best.append(y2[max_index])\n",
    "        param_best.append(parameters[max_index])\n",
    "\n",
    "    return acc_test_best, acc_train_best, y_pred_best, y_true_best, param_best\n",
    "\n",
    "# Used to compare the accuracy of a model against each dataset\n",
    "def modelPlotResults(parameters, acc_train, acc_test, y_pred, y_true, \n",
    "                     xlabel, param_name, fontsize = 15, save_path = \"graphs/\", evolution_param = True):\n",
    "\n",
    "    # Chaging overall font scale\n",
    "    sns.set(font_scale = 1.1)\n",
    "    \n",
    "    # In some cases, like for linear regression, there is no parameter to make evoluate\n",
    "    if evolution_param:\n",
    "\n",
    "        # 1 - Evolution of the test accuracy\n",
    "        plt.figure(figsize = (15, 15))\n",
    "\n",
    "        # Plotting evolution curve for a specific dataset with varying parameter value\n",
    "        for i, a in enumerate(acc_test):\n",
    "            plt.plot(parameters, [a_i * 100 for a_i in a], label = f\"D{i}\", linewidth = 4)\n",
    "        \n",
    "        plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "        plt.ylabel(\"Accuracy [%]\", fontsize = fontsize)\n",
    "        plt.xlabel(xlabel, fontsize = fontsize)\n",
    "        plt.savefig(f\"{save_path}_1.png\")\n",
    "        plt.show()\n",
    "   \n",
    "        acc_test_best, acc_train_best, y_pred_best, y_true_best, k_best = computeBest(parameters, \n",
    "                                                                                      acc_train, \n",
    "                                                                                      acc_test, \n",
    "                                                                                      y_pred, \n",
    "                                                                                      y_true)\n",
    "                                      \n",
    "        # Definition of the xlabel for the bar plot\n",
    "        x_ax_labels_1 = [f\"D{i} - {param_name} = {k_best[i]}\" for i in range(len(acc_train))]\n",
    "        x_ax_labels_2 = [f\"D{i} - {param_name} = {k_best[i]}\" for i in range (len(y_pred))]\n",
    "\n",
    "    else:\n",
    "        x_ax_labels_1 = [f\"D{i}\" for i in range(len(acc_train))]\n",
    "        x_ax_labels_2 = [f\"D{i}\" for i in range (len(y_pred))]\n",
    "        acc_test_best, acc_train_best = acc_test, acc_train\n",
    "        y_pred_best, y_true_best      = y_pred, y_true \n",
    "\n",
    "    # 2 - Bar plot of accuracy \n",
    "    index = [i for i in range(len(acc_train))]\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize = (20, 7))\n",
    "    plt.bar([i - 0.2 for i in index], [a_i * 100 for a_i in acc_train_best], 0.4, label = \"Train\")\n",
    "    plt.bar([i + 0.2 for i in index], [a_i * 100 for a_i in acc_test_best ], 0.4, label = \"Test\")\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_1)\n",
    "    plt.ylabel(\"Accuracy [%]\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_2.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3 - Bar plot of different errors and accuracy measurements\n",
    "    mae, rmse, mdae, r2, auc = [], [], [], [], []\n",
    "    mae, rmse, mdae, r2, auc = computeError(y_true_best, y_pred_best)\n",
    "  \n",
    "    # Used to make x-axis\n",
    "    index = [i for i in range(len(y_pred))]\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize = (20, 12))\n",
    "    plt.subplot(211)\n",
    "    plt.bar([i - 0.2 for i in index], [mae_i *100 for mae_i in mae],     0.2, label = \"Mean Absolute Error\")\n",
    "    plt.bar([i   for i in index],     [rmse_i *100  for rmse_i in rmse], 0.2, label = \"Root Mean Squared Error\")\n",
    "    plt.bar([i + 0.2 for i in index], [mdae_i  *100 for mdae_i in mdae], 0.2, label = \"Median Absolute Error\")\n",
    "    plt.ylabel(\"Error [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_2)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.subplot(212)\n",
    "    plt.bar([i - 0.1 for i in index], [r2_i * 100 for r2_i in r2],    0.2, label = \"R2 Score\")\n",
    "    plt.bar([i + 0.1 for i in index], [auc_i * 100 for auc_i in auc], 0.2, label = \"AUC\")\n",
    "    plt.ylabel(\"Measurement [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_2)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_Error.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Used to compare the accuracy of a model against each others (adaptation for complex models)\n",
    "def modelPlotResultsComplex(y_pred, y_true, xlabels, fontsize = 15, save_path = \"graphs/\"):\n",
    "\n",
    "    # Security\n",
    "    assert len(y_pred) == len(y_true),  f\"Number of predictions = {len(y_pred)},  Number of exact measurements = {len(y_true)}\"\n",
    "    assert len(y_pred) == len(xlabels), f\"Number of predictions = {len(y_pred)}, Number of labels             = {len(xlabels)}\"\n",
    "\n",
    "    # Stores the differents errors and accuracy measurements\n",
    "    mae, rmse, mdae, r2, auc = list(), list(), list(), list(), list()\n",
    "\n",
    "    # Computing everything\n",
    "    mae, rmse, mdae, r2, auc = computeError(y_true, y_pred)\n",
    "\n",
    "    # Used to make x-axis\n",
    "    index = [i for i in range(len(y_pred))]\n",
    "    \n",
    "    # Plotting the results\n",
    "    sns.set(font_scale = 1.1)\n",
    "    plt.figure(figsize = (20, 12))\n",
    "    plt.subplot(211)\n",
    "    plt.bar([i - 0.2 for i in index], [mae_i *100 for mae_i in mae]    , 0.2, label = \"Mean Absolute Error\")\n",
    "    plt.bar([i   for i in index],     [rmse_i *100  for rmse_i in rmse], 0.2, label = \"Root Mean Squared Error\")\n",
    "    plt.bar([i + 0.2 for i in index], [mdae_i  *100 for mdae_i in mdae], 0.2, label = \"Median Absolute Error\")\n",
    "    plt.ylabel(\"Error [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, xlabels)\n",
    "    plt.legend(loc = \"upper left\", fontsize = fontsize)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar([i - 0.1 for i in index], [r2_i * 100 for r2_i in r2],    0.2, label = \"R2 Score\")\n",
    "    plt.bar([i + 0.1 for i in index], [auc_i * 100 for auc_i in auc], 0.2, label = \"AUC\")\n",
    "    plt.ylabel(\"Measurement [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, xlabels)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_Error.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OTHERS --\n",
    "#\n",
    "# Used to display a simple progress bar while training for 1 epoch\n",
    "def progressBar(loss_training, loss_test, r2_test, estimated_time_epoch, nb_epoch_left, percent, width = 40):\n",
    "\n",
    "    # Setting up the useful information\n",
    "    left          = width * percent // 100\n",
    "    right         = width - left\n",
    "    tags          = \"#\" * int(left)\n",
    "    spaces        = \" \" * int(right)\n",
    "    percents      = f\"{percent:.2f} %\"\n",
    "    loss_training = f\"{loss_training * 1:.4f}\"\n",
    "    loss_test     = f\"{loss_test * 1:.4f}\"\n",
    "    r2_test       = f\"{r2_test * 100 * 1:.4f}\"\n",
    "\n",
    "    # Computing timings\n",
    "    estimated_time_total = f\"{nb_epoch_left * estimated_time_epoch:.2f} s\"\n",
    "\n",
    "    # Creation of the string\n",
    "    bar = f\"[{tags}{spaces}] - {percents}  | Loss (Training) = {loss_training} | Loss (Test) = {loss_test} | R2 Metric [%] = {r2_test} | Time left : {estimated_time_total} |\"\n",
    "\n",
    "    # Displaying the progress bar\n",
    "    print(bar, end = \"\\r\", flush = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d4e8035",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 187px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Linear Regression (Example)</p>\n",
    "<hr style=\"color:#c6cde1; width: 187px;\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING -- \n",
    "#\n",
    "# Initialization of the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Computing accuracies\n",
    "lr_accuracy_train, lr_accuracy_test, lr_y_pred, lr_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults([], lr_accuracy_train, lr_accuracy_test, lr_y_pred, lr_y_true, \n",
    "                 xlabel = \"Slope\", param_name = \"Slope\", fontsize = 10, \n",
    "                 save_path = \"graphs/lr/lr\", evolution_param = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "741bdf3e",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1; width: 105px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Regression tree </p>\n",
    "<hr style=\"color:#c6cde1; width: 105px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec680528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "dt_param = np.linspace(5, 20, 15, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "dt_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "dt_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "dt_y_pred = [[] for i in range(len(datasets_X))]\n",
    "dt_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in dt_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = tree.DecisionTreeRegressor(max_depth = depth, random_state=4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        dt_accuracy_train[i].append(acc_1)\n",
    "        dt_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        dt_y_pred[i].append(y_pred)\n",
    "        dt_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e996b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(dt_param, dt_accuracy_train, dt_accuracy_test, dt_y_pred, dt_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, evolution_param = True,\n",
    "                 param_name = \"Depth\", save_path = \"graphs/dt/dt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">K-Neighbors-Regressor</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "k_param = np.arange(1, 100, 10, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "knn_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "knn_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "knn_y_pred = [[] for i in range(len(datasets_X))]\n",
    "knn_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for k in k_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = KNeighborsRegressor(n_neighbors = k)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        knn_accuracy_train[i].append(acc_1)\n",
    "        knn_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        knn_y_pred[i].append(y_pred)\n",
    "        knn_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(k_param, knn_accuracy_train, knn_accuracy_test, knn_y_pred, knn_y_true,\n",
    "                 xlabel = \"Number of k Neighbors - $k$ [-]\", fontsize = 10, \n",
    "                 param_name = \"knn\", save_path = \"graphs/knn/knn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 225px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Linear Support Vector Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 225px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING -- \n",
    "#\n",
    "# Parameters to test for Grid Search\n",
    "C_param = np.linspace(0.001, 1, num=20)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "svr_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "svr_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "svr_y_pred = [[] for i in range(len(datasets_X))]\n",
    "svr_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for c in C_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = LinearSVR(random_state=0, dual = False, loss = \"squared_epsilon_insensitive\", C = c, epsilon = 0.001)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        svr_accuracy_train[i].append(acc_1)\n",
    "        svr_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        svr_y_pred[i].append(y_pred)\n",
    "        svr_y_true[i].append(y_true)\n",
    "\n",
    "# Rounding values of alpha for better display\n",
    "C_param = [round(item, 3) for item in C_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(C_param, svr_accuracy_train, svr_accuracy_test, svr_y_pred, svr_y_true,\n",
    "                 xlabel = \"Regularization parameter - $C$ [-]\", fontsize = 10, evolution_param = True,\n",
    "                 param_name = \"C\", save_path = \"graphs/svr/svr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da56ff",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 115px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Ridge Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 115px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "alpha_param = np.linspace(40, 0.01, 50)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "rr_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "rr_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "rr_y_pred = [[] for i in range(len(datasets_X))]\n",
    "rr_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for alpha in alpha_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = Ridge(alpha = alpha)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        rr_accuracy_train[i].append(acc_1)\n",
    "        rr_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        rr_y_pred[i].append(y_pred)\n",
    "        rr_y_true[i].append(y_true)\n",
    "\n",
    "# Rounding values of alpha for better display\n",
    "alpha_param = [round(item, 2) for item in alpha_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(alpha_param, rr_accuracy_train, rr_accuracy_test, rr_y_pred, rr_y_true,\n",
    "                 xlabel = \"Penalization - alpha [-]\", fontsize = 10, \n",
    "                 param_name = \"alpha\", save_path = \"graphs/rr/rr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 102px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Random Forest</p>\n",
    "<hr style=\"color:#c6cde1; width: 102px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4495ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "rf_max_depth = np.linspace(10, 30, 2, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "rf_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "rf_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "rf_y_pred = [[] for i in range(len(datasets_X))]\n",
    "rf_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in rf_max_depth:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = RandomForestRegressor(max_depth = depth, n_estimators = 20, n_jobs = 4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        rf_accuracy_train[i].append(acc_1)\n",
    "        rf_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        rf_y_pred[i].append(y_pred)\n",
    "        rf_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(rf_max_depth, rf_accuracy_train, rf_accuracy_test, rf_y_pred, rf_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, \n",
    "                 param_name = \"Depth\", save_path = \"graphs/rf/rf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b76b278a",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Extra Trees Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "et_max_depth = np.linspace(10, 30, 2, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "et_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "et_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "et_y_pred = [[] for i in range(len(datasets_X))]\n",
    "et_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in et_max_depth:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = ExtraTreesRegressor(max_depth = depth, n_estimators = 100, n_jobs = 4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        et_accuracy_train[i].append(acc_1)\n",
    "        et_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        et_y_pred[i].append(y_pred)\n",
    "        et_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(et_max_depth, et_accuracy_train, et_accuracy_test, et_y_pred, et_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, \n",
    "                 param_name = \"Depth\", save_path = \"graphs/et/et\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da56ff",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Multi-Layer-Perceptron</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS --\n",
    "# \n",
    "# Number of epochs for the training\n",
    "number_epochs = 2\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Batch size\n",
    "bs = 64\n",
    "\n",
    "# Dimensional factor for the NN architecture\n",
    "size_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- NEURAL NETWORK -- \n",
    "class MLP_PowerPrediction(nn.Module):\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, input_size, nn_size = 2):\n",
    "\n",
    "        # Need to call the super to define child functions\n",
    "        super(MLP_PowerPrediction, self).__init__()\n",
    "\n",
    "        # Used to increase simply the size of the network\n",
    "        size_factor = nn_size\n",
    "\n",
    "        # Contains the fully connected layers\n",
    "        self.fullyConnected_1 = nn.Linear(in_features = input_size,       out_features = 16 * size_factor).double()\n",
    "        self.fullyConnected_2 = nn.Linear(in_features = 16 * size_factor, out_features = 32 * size_factor).double()\n",
    "        self.fullyConnected_3 = nn.Linear(in_features = 32 * size_factor, out_features = 32 * size_factor).double()\n",
    "        self.fullyConnected_4 = nn.Linear(in_features = 32 * size_factor, out_features = 16 * size_factor).double()\n",
    "        self.fullyConnected_5 = nn.Linear(in_features = 16 * size_factor, out_features = 1).double()\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def forward(self, x):\n",
    "        x = self.fullyConnected_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATALOADER --\n",
    "class PowerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "            # Conversion to numpy and double type (needed for torch weight)\n",
    "            X = X.to_numpy().astype(np.double)\n",
    "            y = y[\"TARGETVAR\"].to_numpy().astype(np.double)\n",
    "\n",
    "            # Conversion to torch tensor\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def getDatasets(self):\n",
    "        return self.X, self.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING & TESTING --\n",
    "#\n",
    "# Contains evolution of training and test lost over the epochs for each dataset\n",
    "nn_accuracy_train_total, nn_accuracy_test_total, nn_y_pred_total, nn_y_true_total = list(), list(), list(), list()\n",
    "\n",
    "# Used to compute R2 Metric\n",
    "r2score = R2Score()\n",
    "\n",
    "# Looping over all the datasets\n",
    "for i, dataset_X, dataset_Y in zip(range(len(datasets_X)), datasets_X, datasets_Y):\n",
    "\n",
    "    # Creation of train and test sets\n",
    "    X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(dataset_X, dataset_Y, test_size = 0.3)\n",
    "\n",
    "    # Generation of the datasets\n",
    "    POWER_loader_train   = DataLoader(PowerDataset(X_NN_train, Y_NN_train), batch_size = bs)\n",
    "    X_NN_test, Y_NN_test = PowerDataset(X_NN_test,  Y_NN_test).getDatasets()\n",
    "\n",
    "    # Number of inputs in current datasets\n",
    "    nb_inputs =  len(dataset_X.to_numpy()[0])\n",
    "\n",
    "    # Initalization of the network\n",
    "    model_NN = MLP_PowerPrediction(nb_inputs, nn_size = size_factor) \n",
    "\n",
    "    # ---- Some stuff you don't need to look into ----\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_NN.parameters(), lr = 0.001)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones = [int(number_epochs/2), int(number_epochs * 3/4), int(number_epochs * 7/8)], \n",
    "                                               gamma      = 0.1)\n",
    "\n",
    "    # Used to compute training progression bar (1)\n",
    "    size_train = len(X_NN_train)\n",
    "    epoch_time = 0\n",
    "\n",
    "    # Contains evolution of training and test lost over the epochs\n",
    "    nn_accuracy_train, nn_accuracy_test, nn_y_pred, nn_y_true  = list(), list(), list(), list()\n",
    "\n",
    "    # Display useful information over terminal (0)\n",
    "    section(f\"Neural Network - Training & Testing : Dataset ({i + 1}/{len(datasets_X)})\")\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(number_epochs):\n",
    "\n",
    "        # Used to compute loss\n",
    "        epoch_loss_train  = 0.0\n",
    "        epoch_steps_train = 0\n",
    "        epoch_loss_test   = 0.0\n",
    "        epoch_steps_test  = 0\n",
    "\n",
    "        # Display useful information over terminal (1)\n",
    "        print(\"Epoch : \", epoch + 1, \"/\", number_epochs)\n",
    "\n",
    "        # Used to compute training progression bar (2)\n",
    "        index = bs\n",
    "\n",
    "        # Used to approximate time left for current epoch and in total\n",
    "        start = time.time()\n",
    "\n",
    "        #----------------------\n",
    "        #       Training\n",
    "        #----------------------\n",
    "        # Retreiving a batch of data\n",
    "        for x, y in POWER_loader_train:\n",
    "\n",
    "            # Reseting gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(x)\n",
    "            ytrue = torch.unsqueeze(y, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss = criterion(yhat, ytrue)\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating epoch info ! Would be nice to upgrade it !\n",
    "            epoch_loss_train   += loss.item()\n",
    "            epoch_steps_train  += 1\n",
    "            nb_epoch_left = number_epochs - epoch\n",
    "            percentage    = (index/size_train) * 100 if (index/size_train) <= 1 else 100\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, 0, 0, epoch_time, nb_epoch_left, percentage)\n",
    "            index += bs\n",
    "\n",
    "        # Updating the scheduler to update learning rate !\n",
    "        scheduler.step()\n",
    "\n",
    "        #----------------------\n",
    "        #       Testing\n",
    "        #----------------------\n",
    "        with torch.no_grad():  \n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(X_NN_test)\n",
    "            ytrue = torch.unsqueeze(Y_NN_test, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss_mse = criterion(yhat, ytrue)\n",
    "            loss_r2  = r2score(yhat, ytrue)\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, loss_mse.item(), loss_r2, epoch_time, nb_epoch_left, percentage)\n",
    "\n",
    "        # Updating timing\n",
    "        epoch_time    = time.time() - start\n",
    "\n",
    "        # Updating training and test accuracies\n",
    "        nn_accuracy_train.append(epoch_loss_train/epoch_steps_train)\n",
    "        nn_accuracy_test.append(loss_mse)\n",
    "        nn_y_pred.append(yhat.cpu().detach().numpy())\n",
    "        nn_y_true.append(ytrue.cpu().detach().numpy())\n",
    "\n",
    "        # Just to make sure there is no overlap between progress bar and section\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    # Updating training and test accuracies\n",
    "    nn_accuracy_train_total.append(nn_accuracy_train)\n",
    "    nn_accuracy_test_total.append(nn_accuracy_test)\n",
    "    nn_y_pred_total.append(nn_y_pred)\n",
    "    nn_y_true_total.append(nn_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(np.linspace(1, number_epochs, number_epochs), nn_accuracy_train_total, nn_accuracy_test_total, nn_y_pred_total, nn_y_true_total,\n",
    "                 xlabel = \"Number of epochs [-]\", fontsize = 10, \n",
    "                 param_name = \"Epoch\", save_path = \"graphs/nn/nn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6b1cb5f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Ensemble Methods : Voting & Stacking Regressors\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will try different ways to gather basic methods to improve the accuracy:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Gather methods with the same accuracy inside a voting or stacking classifier;</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTION --\n",
    "#\n",
    "def combine_methods(ensemble_method, methods_to_gather):\n",
    "    #--------------\n",
    "    # Documentation\n",
    "    #--------------\n",
    "    # - ensemble_method   : a string whose values may be either 'stacking' or 'voting'\n",
    "    #\n",
    "    # - methods_to_gather : A list with the methods to gather inside an ensemble regressor\n",
    "    #\n",
    "    if ensemble_method == 'stacking':\n",
    "        model = StackingRegressor(estimators = methods_to_gather, final_estimator = LinearRegression(), n_jobs = 4)\n",
    "\n",
    "    elif ensemble_method == 'voting':\n",
    "        model = VotingRegressor(methods_to_gather, n_jobs = 4)\n",
    "\n",
    "    return model\n",
    "\n",
    "def pred_combine_methods(dataset_X, dataset_Y, first_model_name = 'RandomForest', ensemble_method  = 'voting', \n",
    "                         parameters = [{'n_estimators': [80], 'max_depth': [50]}], number_folds    = 5,\n",
    "                         random_state = 69):\n",
    "    #--------------\n",
    "    # Documentation\n",
    "    #--------------\n",
    "    # - first_model_name : a string with the name of the tree regressor, can be either \n",
    "    #                      'RandomForest' or 'ExtraTreesRegressor'\n",
    "    # - ensemble_method  : a string whose values may be either 'stacking' or 'voting'\n",
    "    # - parameters       : a list of dictionary with the paramers for the GridSearch\n",
    "    # - number_folds     : an integer indicating the number of folds for the GridSearch\n",
    "    # - random_state     : an integer indacting the seed of random objects\n",
    "    #\n",
    "    # Security\n",
    "    assert first_model_name in [\"RandomForest\", \"ExtraTreesRegressor\"], \"First model = RandomForest or ExtraTreesRegressor\"\n",
    "    assert ensemble_method  in [\"stacking\", \"voting\"],                  \"Ensemble method = voting or stacking\"\n",
    "    \n",
    "    # Displaying information over terminal (1)\n",
    "    print('Progression:...')\n",
    "\n",
    "    # Stores all the results from the training session\n",
    "    best_parameters, y_pred_zones, y_true_zones = list(), list(), list()\n",
    "\n",
    "    # Looping over all the different zones\n",
    "    for zone_ID in range(1, 11):\n",
    "        \n",
    "        # Used to have an idea of simulation time (1)\n",
    "        start = time.time()\n",
    "\n",
    "        # ============= Creation of the sets for the corresponding zone =============\n",
    "        x  =  dataset_X[zone_ID - 1].to_numpy()\n",
    "        y  =  dataset_Y[zone_ID - 1][[\"TARGETVAR\"]].to_numpy().ravel()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = random_state)\n",
    "\n",
    "        # ============== Creation of the combined model (1st layer) ==================\n",
    "        r1 = ExtraTreesRegressor(random_state = random_state) if first_model_name == \"ExtraTrees\" else RandomForestRegressor(random_state = random_state)\n",
    "\n",
    "        # Looking for best tree\n",
    "        r1_best_model = GridSearchCV(r1, parameters, cv = number_folds, refit=True, \n",
    "                                     verbose = 0, n_jobs = 4, scoring = 'r2')\n",
    "        \n",
    "        # Fitting on training data\n",
    "        r1_best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Retreiving best parameters\n",
    "        best_parameters.append(r1_best_model.best_params_)\n",
    "\n",
    "        # =========== Creation of the combined model (2nd layer & Training) ==========\n",
    "        r2_best_model = KNeighborsRegressor(n_neighbors=2) \n",
    "\n",
    "        # Initialization of the combined model\n",
    "        combined_model = combine_methods(ensemble_method, [('trees', r1_best_model), ('knn1', r2_best_model)])\n",
    "\n",
    "        # Fitting on training data\n",
    "        combined_model.fit(X_train, y_train)\n",
    "\n",
    "        # ================================  Results ===================================\n",
    "        # Storing results\n",
    "        y_pred_zones += combined_model.predict(X_test).tolist()\n",
    "        y_true_zones += y_test.tolist()\n",
    "\n",
    "        # Computing R2 metric\n",
    "        accuracy_per_zone = combined_model.score(X_test, y_test)\n",
    "\n",
    "        # Used to have an idea of simulation time (2)\n",
    "        end = time.time() - start\n",
    "\n",
    "        # Displaying information over terminal (2)\n",
    "        print(f\"ZONE ID: {zone_ID} - Best parameters of the tree: {best_parameters[zone_ID-1]} \\\n",
    "              - Accuracy : {accuracy_per_zone} - Time left: {end * (10 - zone_ID)} [s]\")\n",
    "\n",
    "    # Displaying information over terminal (3)\n",
    "    print('End')\n",
    "\n",
    "    return y_pred_zones, y_true_zones, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212276af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE SEPARATED DATASETS --\n",
    "#\n",
    "# Define the type of dataset\n",
    "dataset_type = \"separated\"\n",
    "\n",
    "# Normalization parameters\n",
    "norm_parameters = [\"standard\", \"column\"]\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Pipeline\n",
    "loader.pipeline(useMeanVariance    = True, var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = True, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 2,\n",
    "                useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False, SpeedDir_height  = \"both\",\n",
    "                removing           = False)\n",
    "\n",
    "# Finalization\n",
    "loader.finalization(dataset_type = dataset_type)\n",
    "\n",
    "# Creation of the train/test sets\n",
    "X_sep, submit_X_sep, Y_sep, submit_Y_sep = loader.splitTrainTest()\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(X_sep)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Stores all the results\n",
    "y_pred_ensemble, y_true_ensemble = [], []\n",
    "\n",
    "# Testing possible model combinations\n",
    "for m in [\"RandomForest\", \"ExtraTreesRegressor\"]:\n",
    "    for e in [\"voting\", \"stacking\"]:\n",
    "\n",
    "        # Training and testing\n",
    "        y_pred_zones, y_true_zones, _ = pred_combine_methods(X_sep, Y_sep, first_model_name = m, ensemble_method  = e, \n",
    "                                                            parameters = [{'n_estimators': [5], 'max_depth': [20]}], number_folds  = 2, random_state = 69)\n",
    "        y_pred_ensemble.append(y_pred_zones)\n",
    "        y_true_ensemble.append(y_true_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting final results\n",
    "modelPlotResultsComplex(y_pred_ensemble, y_true_ensemble, [\"RF - Voting\", \"RF - Stacking\", \"ET - Voting\", \"ET - Stacking\"], \n",
    "                        fontsize = 15, save_path = f\"graphs/ensemble/ensemble\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6cfcb77",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model Complex - Training | Testing | Plotting results\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Train and test complex model using the optimal datasets found previously;</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60056f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- POWER OF THE CROWD (CLASS) -- \n",
    "class PowerOfTheCrowd():\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, model_generalized, models_specialized):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - model_generalized  : the model that has been trained on all the data\n",
    "        # \n",
    "        # - models_specialized : a list containing the 10 models that have been trained separately, \n",
    "        #                        they should be ordered by increasing ID number.\n",
    "        #\n",
    "        self.model_gen = model_generalized\n",
    "        self.model_spe = models_specialized\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def score(self, x, y_true, average = \"unique\", return_predict = False):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - x       : the input sample in pandas format\n",
    "        #\n",
    "        # - average : determine if the average is computed between the model i and the generalized (unique) \n",
    "        #             or using all the models (all)\n",
    "        # Security\n",
    "        assert average in [\"unique\", \"all\"], \"Average can either be set to two or all\"\n",
    "        \n",
    "        # ---- Averaging over all predictions ----\n",
    "        if average == \"all\":\n",
    "\n",
    "            # Changing to numpy\n",
    "            x      = x.to_numpy()\n",
    "            y_true = y_true[\"TARGETVAR\"].to_numpy()\n",
    "\n",
    "            # ---- Generalized model predictions  ----\n",
    "            y_gen = self.model_gen.predict(x)\n",
    "\n",
    "            # Stores results\n",
    "            y_pred = np.zeros((11, x.shape[0]))\n",
    "\n",
    "            # Computing each separate models predictions\n",
    "            for i, m in enumerate(self.model_spe):\n",
    "                y_pred[i, :] = m.predict(x)                \n",
    "\n",
    "            # Adding generalized models results\n",
    "            y_pred[10, :] = y_gen[:]\n",
    "\n",
    "            # Computing final score\n",
    "            return np.mean(y_pred, axis = 0), y_true if return_predict else r2_score(y_true, np.mean(y_pred, axis = 0))\n",
    "\n",
    "        # ---- Averaging of corresponding specialized models and generalized model ----\n",
    "        if average == \"unique\":\n",
    "\n",
    "            # Stores all the results\n",
    "            y_pred       = np.empty((0))\n",
    "            y_true_final = np.empty((0))\n",
    "\n",
    "            # Looping over the different zones\n",
    "            for zone_ID in range(1, 11):\n",
    "\n",
    "                # Extracting sub datasets\n",
    "                Xi = x[x[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "                Yi = y_true[\"TARGETVAR\"][y_true[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "\n",
    "                # Security\n",
    "                if len(Xi) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ---- Generalized model predictions  ----\n",
    "                y_gen = self.model_gen.predict(Xi)\n",
    "\n",
    "                # ---- Specialized model predictions  ----\n",
    "                y_spe = self.model_spe[zone_ID - 1].predict(Xi)\n",
    "\n",
    "                # ---- Computing mean of the results ----\n",
    "                y_mean = np.add(y_gen, y_spe)/2\n",
    "\n",
    "                # ---- Concatenation of the results ----\n",
    "                y_pred       = np.concatenate((y_pred, y_mean))\n",
    "                y_true_final = np.concatenate((y_true_final, Yi))\n",
    "\n",
    "            # Computing final score\n",
    "            return y_pred, y_true_final if return_predict else r2_score(y_true_final, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to retreive an empty model (to be used by grid search afterward)\n",
    "def getModel(model_name = \"knn\"):\n",
    "    if model_name == \"rt\":\n",
    "        return DecisionTreeRegressor()\n",
    "    if model_name == \"knn\":\n",
    "        return KNeighborsRegressor()\n",
    "    if model_name == \"svr\":\n",
    "        return LinearSVR(dual = False, epsilon = 0.01, loss = 'squared_epsilon_insensitive', random_state = 69)\n",
    "    if model_name == \"rr\":\n",
    "        return Ridge()\n",
    "    if model_name == \"rf\":\n",
    "        return RandomForestRegressor(random_state = 69, n_jobs = 4)\n",
    "    if model_name == \"er\":\n",
    "        return ExtraTreesRegressor(random_state = 69, n_jobs = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8256452",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1;\"></hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE DATASETS FOR THE COMPLEX MODELS --\n",
    "#\n",
    "# Note : Each pipeline will generate the optimal dataset for the method tested ! \n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X_complex, datasets_X_submit_complex, datasets_Y_complex, datasets_Y_submit_complex = list(), list(), list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Regression tree\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# K-Nearest-Neighbors\n",
    "loader.pipeline(useMeanVariance    = True, window_MV  = 12,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = True, window_ZON = 3,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Linear Support Vector Regression\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = True,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Ridge Regression\n",
    "loader.pipeline(useMeanVariance    = True, window_MV = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# RandomForestRegressor\n",
    "loader.pipeline(useMeanVariance    = True,  window_MV  = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# ExtraTreesRegressor\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(datasets_X_complex)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebcc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS FOR TRAINING --\n",
    "#\n",
    "# Contains the list of models to test\n",
    "model_complex_list = [\"rt\", \"knn\", \"svr\", \"rr\", \"rf\", \"er\"]\n",
    "\n",
    "# Model (specialiez) parameters to be tested using a gridsearch\n",
    "model_complex_parameters_specialized = [{\"max_depth\"   :[20]                         },\n",
    "                                        {\"n_neighbors\" :[2]                          },\n",
    "                                        {\"C\"           :[0.005]                      },\n",
    "                                        {\"alpha\"       :[7.36]                       },\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]},\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]}\n",
    "                                        ]\n",
    "\n",
    "# Model (generalized) parameters to use\n",
    "model_complex_parameters_generalized = [{\"max_depth\"   :[20]                         },\n",
    "                                        {\"n_neighbors\" :[2]                          },\n",
    "                                        {\"C\"           :[0.005]                      },\n",
    "                                        {\"alpha\"       :[7.36]                       },\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]},\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]}\n",
    "                                        ]\n",
    "#------------\n",
    "#  Security\n",
    "#------------\n",
    "assert len(model_complex_list) == len(datasets_X_complex),                   f\"Number of datasets = {len(datasets_X_complex)}, Number of models           = {len(model_complex_list)}\"\n",
    "assert len(model_complex_list) == len(model_complex_parameters_specialized), f\"Number of datasets = {len(datasets_X_complex)}, Number of parameters (spe) = {len(model_complex_parameters_specialized)}\"\n",
    "assert len(model_complex_list) == len(model_complex_parameters_generalized), f\"Number of datasets = {len(datasets_X_complex)}, Number of parameters (gen) = {len(model_complex_parameters_generalized)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c59909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING THE COMPLEX MODELS --\n",
    "#\n",
    "# Stores all the complex models created\n",
    "model_complex_trained = []\n",
    "\n",
    "# Stores all the test sets for evaluation afterwards\n",
    "X_test_complex = []\n",
    "Y_test_complex = []\n",
    "\n",
    "# Looping over model, their corresponding datasets and parameters\n",
    "for X_set, Y_set, m, param_spe, param_gen in zip(datasets_X_complex, datasets_Y_complex, model_complex_list, model_complex_parameters_specialized, model_complex_parameters_generalized):\n",
    "\n",
    "    # Displaying information over terminal (1)\n",
    "    section(f\"Model : {m}\")\n",
    "\n",
    "    # Stores all the individual models\n",
    "    models_sep = []\n",
    "\n",
    "    # Stores the train and test set of the generalized model (concatenation of the small one to avoid bias)\n",
    "    X_train_generalized = pd.DataFrame()\n",
    "    Y_train_generalized = pd.DataFrame()\n",
    "    X_test_generalized  = pd.DataFrame()\n",
    "    Y_test_generalized  = pd.DataFrame()\n",
    "\n",
    "    # -------- Separated Models -------- \n",
    "    for zone_ID in range(1, 11):\n",
    "\n",
    "        # Retreiving corresponding data\n",
    "        Xi = copy.deepcopy(X_set[X_set[\"ZONEID\"] == zone_ID])\n",
    "        Yi = copy.deepcopy(Y_set[Y_set[\"ZONEID\"] == zone_ID])\n",
    "\n",
    "        # Creation of training and testing sets\n",
    "        X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(Xi, Yi, test_size = 0.3)\n",
    "\n",
    "        # Adding datasets\n",
    "        X_train_generalized  = pd.concat([X_train_generalized, X_NN_train], axis = 0)\n",
    "        Y_train_generalized  = pd.concat([Y_train_generalized, Y_NN_train], axis = 0)\n",
    "        X_test_generalized   = pd.concat([X_test_generalized,  X_NN_test] , axis = 0)\n",
    "        Y_test_generalized   = pd.concat([Y_test_generalized,  Y_NN_test] , axis = 0)\n",
    "\n",
    "        # Intialization of the model\n",
    "        model = GridSearchCV(getModel(m), param_spe, n_jobs = 4)\n",
    "\n",
    "        # Fitting the data\n",
    "        model.fit(X_NN_train.to_numpy(), Y_NN_train[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "        # Storing the model\n",
    "        models_sep.append(model)\n",
    "\n",
    "        # Computing score\n",
    "        score_spe = model.score(X_NN_test.to_numpy(), Y_NN_test[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "        # Displaying information over terminal (2)\n",
    "        print(f\"Zone {zone_ID}/10 - Best parameter value = {model.best_params_} - Accuracy = {score_spe}\")\n",
    "\n",
    "    # -------- Generalized Model --------\n",
    "    #\n",
    "    # Initialization of the model\n",
    "    model_gen = GridSearchCV(getModel(m), param_gen)\n",
    "\n",
    "    # Fitting the data\n",
    "    model_gen.fit(X_train_generalized.to_numpy(), Y_train_generalized[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "    # Computing score\n",
    "    score_gen = model.score(X_NN_test.to_numpy(), Y_NN_test[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "    # Displaying information over terminal (2)\n",
    "    print(f\"Zone ALL - Best parameter value = {model_gen.best_params_} - Accuracy = {score_gen}\")\n",
    "\n",
    "    # -------- Complex Model --------\n",
    "    #\n",
    "    # Intialization of the complex model\n",
    "    model_final = PowerOfTheCrowd(model_gen, models_sep)\n",
    "\n",
    "    # Stores all the complex models created\n",
    "    model_complex_trained.append(model_final)\n",
    "    X_test_complex.append(X_test_generalized)\n",
    "    Y_test_complex.append(Y_test_generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EVALUATION OF THE MODEL AND COMPARING RESULTS ---\n",
    "#\n",
    "# Determine if all the separated models are used for prediction or just the corresponding one\n",
    "avg = \"all\"\n",
    "\n",
    "# Stores the predicted and true results\n",
    "y_predict_final = []\n",
    "y_true_final    = []\n",
    "\n",
    "# Testing all the models\n",
    "for x, y, m in zip(X_test_complex, Y_test_complex, model_complex_trained):\n",
    "\n",
    "    # Evaluation of the complex model\n",
    "    y_pred, y_true = m.score(x, y, average = avg, return_predict = True)\n",
    "\n",
    "    # Adding everything\n",
    "    y_predict_final.append(y_pred)\n",
    "    y_true_final.append(y_true)\n",
    "\n",
    "# Definition of the labels\n",
    "labels = [\"RT\", \"KNN\", \"SVR\", \"RR\", \"RF\", \"ER\"]\n",
    "\n",
    "# Plotting final results\n",
    "modelPlotResultsComplex(y_predict_final, y_true_final, labels, fontsize = 15, save_path = f\"graphs/complex/complex_{avg}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c67259b4",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model complex - Neural Network\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Create a complex model using a Neural Network</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdff0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS --\n",
    "# \n",
    "# Number of epochs for the training\n",
    "number_epochs_c = 4\n",
    "\n",
    "# Learning rate\n",
    "lr_c = 0.001\n",
    "\n",
    "# Batch size\n",
    "bs_c = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE DATASETS FOR THE NEURAL NETWORK COMPLEX MODELS --\n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X_complex_NN, datasets_Y_complex_NN = list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Regression tree\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, _, Y, _ = loader.splitTrainTest()\n",
    "\n",
    "# 1 - Adding separate datasets\n",
    "for i in range(1, 11):\n",
    "    datasets_X_complex_NN.append(copy.deepcopy(X[X[\"ZONEID\"] == i]))\n",
    "    datasets_Y_complex_NN.append(copy.deepcopy(Y[Y[\"ZONEID\"] == i]))\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(datasets_X_complex_NN)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING & TESTING THE COMPLEX MODEL --\n",
    "#\n",
    "# Stores the accuracy of the training and testing\n",
    "nn_accuracy_train = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_accuracy_test  = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_y_pred         = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_y_true         = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "\n",
    "# Stores all the models that have been created\n",
    "model_generalized_NN  = 0\n",
    "models_specialized_NN = []\n",
    "\n",
    "# Stores the test sets\n",
    "X_test_complex  = pd.DataFrame()\n",
    "Y_test_complex  = pd.DataFrame()\n",
    "X_train_complex = pd.DataFrame()\n",
    "Y_train_complex = pd.DataFrame()\n",
    "\n",
    "# Used to compute R2 score\n",
    "rscore = R2Score()\n",
    "\n",
    "# Looping over all the datasets\n",
    "for i, dataset_X, dataset_Y in zip(range(len(datasets_X_complex_NN)), datasets_X_complex_NN, datasets_Y_complex_NN):\n",
    "    \n",
    "    # Creation of train and test sets\n",
    "    X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(dataset_X, dataset_Y, test_size = 0.3)\n",
    "\n",
    "    # Storing the test sets except for the generalized one\n",
    "    if i != len(datasets_X_complex_NN) - 1:\n",
    "        X_test_complex  = pd.concat([X_test_complex, X_NN_test], axis=0)\n",
    "        Y_test_complex  = pd.concat([Y_test_complex, Y_NN_test], axis=0)\n",
    "        X_train_complex = pd.concat([X_train_complex, X_NN_train], axis=0)\n",
    "        Y_train_complex = pd.concat([Y_train_complex, Y_NN_train], axis=0)\n",
    "    else:\n",
    "        X_NN_train = X_train_complex\n",
    "        X_NN_test  = X_test_complex\n",
    "        Y_NN_train = Y_train_complex\n",
    "        Y_NN_test  = Y_test_complex\n",
    "    \n",
    "    # Generation of the datasets\n",
    "    POWER_loader_train   = DataLoader(PowerDataset(X_NN_train, Y_NN_train), batch_size = bs_c)\n",
    "    X_NN_test, Y_NN_test = PowerDataset(X_NN_test,  Y_NN_test).getDatasets()\n",
    "\n",
    "    # Number of inputs in current datasets\n",
    "    nb_inputs =  len(dataset_X.to_numpy()[0])\n",
    "\n",
    "    # Initalization of the network\n",
    "    model_NN = MLP_PowerPrediction(nb_inputs)\n",
    "\n",
    "    # ---- Some stuff you don't need to look into ----\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_NN.parameters(), lr = lr_c)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones = [int(number_epochs_c/2), int(number_epochs_c * 3/4), int(number_epochs_c * 7/8)], \n",
    "                                               gamma      = 0.1)\n",
    "\n",
    "    # Used to compute training progression bar (1)\n",
    "    size_train = len(X_NN_train)\n",
    "    epoch_time = 0\n",
    "\n",
    "    # Display useful information over terminal (0)\n",
    "    section(f\"Neural Network - Training & Testing : Dataset ({i + 1}/{len(datasets_X_complex_NN)})\")\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(number_epochs_c):\n",
    "\n",
    "        # Used to compute loss\n",
    "        epoch_loss_train  = 0.0\n",
    "        r2_loss_train     = 0.0\n",
    "        epoch_steps_train = 0\n",
    "        epoch_loss_test   = 0.0\n",
    "        epoch_steps_test  = 0\n",
    "\n",
    "        # Display useful information over terminal (1)\n",
    "        print(\"Epoch : \", epoch + 1, \"/\", number_epochs_c)\n",
    "\n",
    "        # Used to compute training progression bar (2)\n",
    "        index = bs_c\n",
    "\n",
    "        # Used to approximate time left for current epoch and in total\n",
    "        start = time.time()\n",
    "\n",
    "        #----------------------\n",
    "        #       Training\n",
    "        #----------------------\n",
    "        # Retreiving a batch of data\n",
    "        for x, y in POWER_loader_train:\n",
    "\n",
    "            # Reseting gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(x)\n",
    "            ytrue = torch.unsqueeze(y, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss = criterion(yhat, ytrue)\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating epoch info ! Would be nice to upgrade it !\n",
    "            epoch_loss_train   += loss.item()\n",
    "            r2_loss_train      += rscore(yhat, ytrue).detach().numpy()\n",
    "            epoch_steps_train  += 1\n",
    "            nb_epoch_left = number_epochs_c - epoch\n",
    "            percentage    = (index/size_train) * 100 if (index/size_train) <= 1 else 100\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, 0, r2_loss_train/epoch_steps_train, epoch_time, nb_epoch_left, percentage)\n",
    "            index += bs\n",
    "\n",
    "        # Updating the scheduler to update learning rate !\n",
    "        scheduler.step()\n",
    "\n",
    "        #----------------------\n",
    "        #       Testing\n",
    "        #----------------------\n",
    "        with torch.no_grad():  \n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(X_NN_test)\n",
    "            ytrue = torch.unsqueeze(Y_NN_test, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss_mse = criterion(yhat, ytrue)\n",
    "            \n",
    "            # Adding preditions for AUC and R2 computation\n",
    "            nn_y_pred[i].append(np.asarray([y[0] for y in yhat.detach().numpy()]))\n",
    "            nn_y_true[i].append(np.asarray([y[0] for y in ytrue.detach().numpy()]))\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, loss_mse.item(), rscore(yhat, ytrue), epoch_time, nb_epoch_left, percentage)\n",
    "\n",
    "        # Updating timing\n",
    "        epoch_time    = time.time() - start\n",
    "\n",
    "        # Updating training and test accuracies\n",
    "        nn_accuracy_train[i].append(r2_loss_train/epoch_steps_train)\n",
    "        nn_accuracy_test[i].append(rscore(yhat, ytrue))\n",
    "\n",
    "        # Just to make sure there is no overlap between progress bar and section\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Storing the models\n",
    "        if i == len(datasets_X_complex_NN) - 1:\n",
    "            model_generalized_NN  = model_NN\n",
    "        else:\n",
    "            models_specialized_NN.append(model_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96facbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- POWER OF THE CROWD (Neural Network Version) -- \n",
    "class PowerOfTheCrowdNN():\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, model_generalized, models_specialized):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - model_generalized  : the model that has been trained on all the data\n",
    "        # \n",
    "        # - models_specialized : a list containing the 10 models that have been trained separately, \n",
    "        #                        they should be ordered by increasing ID number.\n",
    "        #\n",
    "        self.model_gen = model_generalized\n",
    "        self.model_spe = models_specialized\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def score(self, x, y_true, average = \"unique\", return_predict = False):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - x       : the input sample in pandas format\n",
    "        #\n",
    "        # - average : determine if the average is computed between the model i and the generalized (unique) \n",
    "        #             or using all the models (all)\n",
    "        # Security\n",
    "        assert average in [\"unique\", \"all\"], \"Average can either be set to two or all\"\n",
    "        \n",
    "        # ---- Averaging over all predictions ----\n",
    "        if average == \"all\":\n",
    "\n",
    "            # Changing to numpy\n",
    "            x         = torch.from_numpy(x.to_numpy())\n",
    "            y_true_np = y_true[\"TARGETVAR\"].to_numpy()\n",
    "            y_true    = torch.from_numpy(y_true_np)\n",
    "\n",
    "            # ---- Generalized model predictions  ----\n",
    "            y_gen = np.squeeze(self.model_gen.forward(x).detach().numpy(), axis = 1)    \n",
    "\n",
    "            # Stores results\n",
    "            y_pred = np.zeros((11, x.shape[0]))\n",
    "\n",
    "            # Computing each separate models predictions\n",
    "            for i, m in enumerate(self.model_spe):\n",
    "                y_pred[i, :] = np.squeeze(m.forward(x).detach().numpy(), axis = 1)                \n",
    "\n",
    "            # Adding generalized models results\n",
    "            y_pred[10, :] = y_gen[:]\n",
    "\n",
    "            # Computing final score\n",
    "            return np.mean(y_pred, axis = 0), y_true_np if return_predict else r2_score(y_true_np, np.mean(y_pred, axis = 0))\n",
    "\n",
    "        # ---- Averaging of corresponding specialized models and generalized model ----\n",
    "        if average == \"unique\":\n",
    "\n",
    "            # Stores all the results\n",
    "            y_pred       = np.empty((0))\n",
    "            y_true_final = np.empty((0))\n",
    "\n",
    "            # Looping over the different zones\n",
    "            for zone_ID in range(1, 11):\n",
    "\n",
    "                # Extracting sub datasets\n",
    "                Xi    = torch.from_numpy(x[x[\"ZONEID\"] == zone_ID].to_numpy())\n",
    "                Yi_np = y_true[\"TARGETVAR\"][y_true[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "                Yi    =  torch.from_numpy(Yi_np)\n",
    "\n",
    "                # Security\n",
    "                if len(Xi) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ---- Generalized model predictions  ----\n",
    "                y_gen = np.squeeze(self.model_gen.forward(Xi).detach().numpy(), axis = 1)\n",
    "\n",
    "                # ---- Specialized model predictions  ----\n",
    "                y_spe = np.squeeze(self.model_spe[zone_ID - 1].forward(Xi).detach().numpy(), axis = 1)\n",
    "\n",
    "                # ---- Computing mean of the results ----\n",
    "                y_mean = np.add(y_gen, y_spe)/2\n",
    "\n",
    "                # ---- Concatenation of the results ----\n",
    "                y_pred       = np.concatenate((y_pred, y_mean))\n",
    "                y_true_final = np.concatenate((y_true_final, Yi_np))\n",
    "\n",
    "            # Computing final score\n",
    "            return y_pred, y_true_final if return_predict else r2_score(y_true_final, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- EVALUATION OF THE MODEL AND COMPARING RESULTS --\n",
    "#\n",
    "# Determine if all the separated models are used for prediction or just the corresponding one\n",
    "avg = \"unique\"\n",
    "\n",
    "# Creation of the complex model\n",
    "model_complex_NN = PowerOfTheCrowdNN(model_generalized_NN, models_specialized_NN)\n",
    "\n",
    "# Computing predictions\n",
    "y_pred, y_true = model_complex_NN.score(X_test_complex, Y_test_complex, average = avg, return_predict = True)\n",
    "\n",
    "print(\"R2 Metric:\", r2_score(y_true, y_pred))\n",
    "\n",
    "# Plotting final results\n",
    "modelPlotResultsComplex([y_pred], [y_true], [\"Comple Neural Network\"], fontsize = 15, save_path = f\"graphs/complex_nn/complex_nn_{avg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6970a6b860234838f15385a694e4c719e6911821bb317b2dd9580ae5d017ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
