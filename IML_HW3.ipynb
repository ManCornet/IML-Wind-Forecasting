{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8531373-cd83-40d0-bbc2-28b641c208e6",
   "metadata": {},
   "source": [
    "<img src=\"assets/background_notebook.jpg\" />\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2.5vw; color:#c6cde1; font-weight:bold;\">\n",
    "    Introduction to machine learning - Project\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<b>Introduction</b><br><br>\n",
    "The purpose of this project is to design a model to predict wind power 24h ahead in 10 zones, corresponding to 10 wind farms located in Australia.<br><br>\n",
    "<b>Authors</b><br><br> \n",
    "<i>Camille Bosch, Manon Cornet</i> and <i>Victor Mangeleer</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b7eac",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Initialization\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Initialize all the librairies needed for the project;</li>\n",
    "        <li style=\"margin-bottom:10px\">Define basic functions.</li>\n",
    "    </ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LIBRAIRIES --\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, median_absolute_error\n",
    "\n",
    "# -- Deep Learning Librairies --\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Allow notebook to plot in terminal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b90a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTION --\n",
    "#\n",
    "# Used to print a basic section title in terminal\n",
    "def section(title):\n",
    "\n",
    "    # Number of letters to determine section size\n",
    "    title_size = len(title)\n",
    "\n",
    "    # Section title boundaries\n",
    "    boundary  = \"-\"\n",
    "    for i in range(title_size + 1):\n",
    "        boundary += \"-\"\n",
    "    \n",
    "    # Printing section\n",
    "    print(boundary)\n",
    "    print(f\" {title} \")\n",
    "    print(boundary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd81e84f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Initialization | First look\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Load the orginal datasets (X and y);</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the head of the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Make an histogram of the speeds;</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the total speed vs power curve;</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe the evolution of the speed.</li>\n",
    "    </ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5da1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LOADING ORIGINAL DATASETS --\n",
    "#\n",
    "# Stores the original dataset\n",
    "dataset_original_X = []\n",
    "dataset_original_Y = []\n",
    "\n",
    "# Load the original dataset\n",
    "for i in range(1, 11):\n",
    "    dataset_original_X.append(pd.read_csv(f\"data/original/X_Zone_{i}.csv\"))\n",
    "    dataset_original_Y.append(pd.read_csv(f\"data/original/Y_Zone_{i}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- HEAD OF THE DATASETS --\n",
    "section(\"WIND TURBINE 1 - X Dataset\")\n",
    "print(dataset_original_X[0].head())\n",
    "section(\"WIND TURBINE 1 - Y Dataset\")\n",
    "print(dataset_original_Y[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- HISTOGRAM OF THE SPEEDS --\n",
    "#\n",
    "# Extracting only relevant variables\n",
    "dataset_X1_relevant = dataset_original_X[0][[\"U10\", \"U100\", \"V10\", \"V100\"]]\n",
    "dataset_Y1_relevant = dataset_original_Y[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]   # /!\\ Removing test samples (y = -1) /!\\\n",
    "dataset_Y1_relevant = dataset_Y1_relevant[[\"TARGETVAR\"]]\n",
    "\n",
    "# Observing distributions\n",
    "dataset_X1_relevant.hist(bins = 240, figsize = (20, 15))\n",
    "dataset_Y1_relevant.hist(bins = 40, figsize = (16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0abd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING WIND VS POWER --\n",
    "#\n",
    "# Removing test data\n",
    "dataset_X_clean = dataset_original_X[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]\n",
    "dataset_Y_clean = dataset_original_Y[0][dataset_original_Y[0][\"TARGETVAR\"] >= 0]\n",
    "\n",
    "# Computing total wind speed\n",
    "u_wind   = dataset_X_clean[[\"U100\"]].to_numpy()\n",
    "v_wind   = dataset_X_clean[[\"V100\"]].to_numpy()\n",
    "wind_tot = np.sqrt(u_wind**2 + v_wind**2)\n",
    "\n",
    "# Retreiving power\n",
    "power = dataset_Y_clean[[\"TARGETVAR\"]].to_numpy()\n",
    "\n",
    "# To see more clearly, one sample out of 2 is removed\n",
    "for i in range(1):\n",
    "    wind_tot = wind_tot[1::2]\n",
    "    power    = power[1::2]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(wind_tot, power, s = 3)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Speed [m/s]\")\n",
    "plt.ylabel(\"Normalized Power [-]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING AUTO-CORRELATIONS --\n",
    "auto_corr_plot = plot_acf(dataset_original_X[0][\"U100\"], lags = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412dc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OBSERVING SPEED EVOLUTION --\n",
    "#\n",
    "# Retreiving first wind turbine\n",
    "X_observation = dataset_original_X[0]\n",
    "\n",
    "# Number of hours in a year\n",
    "year = 8760\n",
    "\n",
    "# Factor to scale down our timeline (f = 2, i.e. observing 6 months)\n",
    "scale = 1\n",
    "\n",
    "# Smoothening (number of values taken for averaging)\n",
    "smooth = 2\n",
    "\n",
    "# Speed to plot the evolution\n",
    "speeds = [\"U10\"]\n",
    "\n",
    "# ---------- Plotting ----------\n",
    "# Note: Rolling allows us to average the values which \"smooth out\" the curve for better visibility\n",
    "for s in speeds:\n",
    "    X_observation.iloc[0          : int(year/scale)         ].rolling(smooth).sum().plot(y = s, use_index = True, figsize = (20, 5))\n",
    "    X_observation.iloc[int(year) : int(year * (1 + 1/scale))].rolling(smooth).sum().plot(y = s, use_index = True, figsize = (20, 5), xlabel = \"TimeSlice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ec0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SEASONAL OBSERVATIONS --\n",
    "#\n",
    "# Observing seasonal evolution of an arbitrary speed\n",
    "X_observation = dataset_original_X[0][\"U100\"]\n",
    "\n",
    "# Coputing decomposition\n",
    "seasonal_decomp = seasonal_decompose(X_observation, model = \"additive\", period = int(len(X_observation)/12))\n",
    "\n",
    "# Showing evolutions\n",
    "print(seasonal_decomp.plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c306f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Modifying | DataLoader | Correlation matrix\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Define functions used to modify/improve (hopefully) the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Define the dataloader, i.e. a custom class used to easily apply modifications to the datasets;</li>\n",
    "        <li style=\"margin-bottom:10px\">Compute and observe the correlation matrix between all possible modifications.</li>\n",
    "    </ul> \n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb17e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to compute the mean and variance of a variable over some timeslices (number defined by the window size) in the dataset\n",
    "def computeMeanVariance(datasets, \n",
    "                        variables = [\"U100\", \"V100\"],\n",
    "                        window    = 24,\n",
    "                        variance  = True):\n",
    "\n",
    "    # Security\n",
    "    assert window > 1, \"Window size must be greater than 1 to compute mean and var\"\n",
    "\n",
    "    # Looping over all the datasets\n",
    "    for d in datasets:\n",
    "\n",
    "        # Looping over the variables whose mean and var must be computed\n",
    "        for v in variables:\n",
    "\n",
    "            # Retreiving data \n",
    "            data = d.loc[: , [v]].to_numpy()\n",
    "\n",
    "            # Stores mean and variance (1st and 2nd : mean = their value, var = 0 otherwise NAN problem while computation)\n",
    "            mean = [data[0][0], data[1][0]]\n",
    "            var  = [0, 0]\n",
    "\n",
    "            for i in range(2, len(data)):\n",
    "\n",
    "                # Start and end index for computation\n",
    "                index_start = i - window if i - window >= 0 else 0\n",
    "                index_end   = i - 1 if i - 1 >= 0 else 0\n",
    "\n",
    "                # Computing mean and variance (much faster using numpy variables)\n",
    "                mean.append(np.mean(data[index_start:index_end]))\n",
    "                var.append(np.var(data[index_start:index_end]))\n",
    "            \n",
    "            # Adding the new data to dataset\n",
    "            d[f\"{v}_mean\"] = mean\n",
    "            if variance:\n",
    "                d[f\"{v}_var\"] = var\n",
    "\n",
    "# Used to compute the instantenous mean and variance of a variable accross multiple datasets\n",
    "def computeZonalValue(datasets, \n",
    "                      variables = [\"U100\", \"V100\"],\n",
    "                      variance  = True):\n",
    "\n",
    "    # Security\n",
    "    assert len(datasets) > 1, \"To compute mean and var, at least 2 datasets are needed\"\n",
    "\n",
    "    # Looping over the variables whose mean and var must be computed\n",
    "    for v in variables:\n",
    "\n",
    "        # Number of samples\n",
    "        nb_samples = len(datasets[0])\n",
    "\n",
    "        # Stores all the different values in numpy matrix for efficient computation\n",
    "        data = np.zeros((nb_samples, len(datasets)))\n",
    "\n",
    "        # Retreiving all the corresponding data\n",
    "        for i, d in enumerate(datasets):\n",
    "            \n",
    "            # Squeeze is there to remove useless dimension\n",
    "            data[:, i] = np.squeeze(d.loc[: , [v]].to_numpy())\n",
    "\n",
    "        # Computing mean and variance (much faster using numpy variables)\n",
    "        mean = np.mean(data, axis = 1) # Axis = 1 to make mean over each row\n",
    "        var  = np.var(data, axis = 1)\n",
    "\n",
    "        # Adding new data to all the datasets\n",
    "        for d in datasets:\n",
    "            d[f\"{v}_mean\"] = mean\n",
    "            if variance:\n",
    "                d[f\"{v}_var\"] = var\n",
    "\n",
    "# Used to add the value taken by a given variable over the past samples\n",
    "def addPastTime(datasets,\n",
    "                variables = [\"U100\", \"V100\"],\n",
    "                window    = 3):\n",
    "\n",
    "    # Security\n",
    "    assert window > 0, \"Window size must be greater than 0 to add past samples\"\n",
    "\n",
    "    # Looping over the datasets\n",
    "    for d in datasets:\n",
    "\n",
    "        # Looping over the different columns\n",
    "        for i, v in enumerate(variables):\n",
    "\n",
    "            # Retrieving current data\n",
    "            data = d[[v]].to_numpy()\n",
    "\n",
    "            # Stores all the past results\n",
    "            former_data = np.zeros((len(data), window))\n",
    "\n",
    "            # Looping over the corresponding data\n",
    "            for j in range(len(data)):\n",
    "\n",
    "                # Start and end index for retreiving values\n",
    "                index_start = j - window if j - window >= 0 else 0\n",
    "                index_end   = j if j - 1 >= 0 else 0\n",
    "                \n",
    "                # Retrieve corresponding value\n",
    "                values = data[index_start:index_end]\n",
    "\n",
    "                # Fixing case where looking at starting indexes < window size\n",
    "                if len(values) != window:\n",
    "                    values = np.append(np.zeros((window - len(values), 1)), values)\n",
    "\n",
    "                # Placing the data (such that by reading left to right: t - 1, t - 2, t - 3, ...)\n",
    "                for k, val in enumerate(values):\n",
    "                        former_data[j][k] = val\n",
    "\n",
    "            # Addding past results in the dataset\n",
    "            for t in range(window):\n",
    "                d[f\"{v}_(t-{window - t})\"] = former_data[:, t]\n",
    "\n",
    "# Used to remove specific columns from the dataset\n",
    "def remove(datasets, var_removed):\n",
    "    for d in datasets:\n",
    "        for v in var_removed:\n",
    "            d.drop(v, inplace = True, axis = 1)\n",
    "\n",
    "# Used to normalize specific columns from the dataset\n",
    "def normalize(datasets,\n",
    "              norm_type = \"max_abs\",\n",
    "              data_type = \"column\",\n",
    "              variables = [\"U10\", \"V10\", \"U100\", \"V100\"]):\n",
    "\n",
    "    # Security\n",
    "    assert norm_type in [\"max_abs\", \"standard\", \"robust\"], \"Normalization type = max_abs, standard and robust\"\n",
    "    assert data_type in [\"column\", \"all\"],                 \"Data type = column, all\"\n",
    "\n",
    "    # Normalization by columns\n",
    "    if data_type == \"column\":\n",
    "\n",
    "        # Looping overall the datasets\n",
    "        for d in datasets:\n",
    "\n",
    "            # Current data\n",
    "            data = d[variables].to_numpy()\n",
    "\n",
    "            # Normalization\n",
    "            if norm_type == \"max_abs\":\n",
    "                scaled_features = MaxAbsScaler().fit_transform(data)\n",
    "            elif norm_type == \"standard\":\n",
    "                scaled_features = StandardScaler().fit_transform(data)\n",
    "            elif norm_type == \"robust\":\n",
    "                scaled_features = RobustScaler().fit_transform(data)\n",
    "\n",
    "            # Updating values\n",
    "            d[variables] = scaled_features\n",
    "\n",
    "    # Normalization on the whole dataset\n",
    "    elif data_type == \"all\":\n",
    "\n",
    "        # Concatenation of all the dataset for the sake of simplicity\n",
    "        data = pd.concat(datasets, keys=[i for i in range(len(datasets))])\n",
    "\n",
    "        # Current data\n",
    "        data_np = data[variables].to_numpy()\n",
    "\n",
    "        # Normalization\n",
    "        if norm_type == \"max_abs\":\n",
    "            scaled_features = MaxAbsScaler().fit_transform(data_np)\n",
    "        elif norm_type == \"standard\":\n",
    "            scaled_features = StandardScaler().fit_transform(data_np)\n",
    "        elif norm_type == \"robust\":\n",
    "            scaled_features = RobustScaler().fit_transform(data_np)\n",
    "\n",
    "        # Updating values\n",
    "        data[variables] = scaled_features\n",
    "\n",
    "        # Re-creation of the datasets\n",
    "        for i in range(len(datasets)):\n",
    "            datasets[i] = data.loc[i, :]\n",
    "\n",
    "# Used to retrieve the wind direction and the wind speed from meridional and zonal comp. and add them in the dataset\n",
    "def wind_comp(datasets, \n",
    "              columns      = \"both\", \n",
    "              speed_height = \"both\"):\n",
    "\n",
    "    # Security\n",
    "    assert columns in [\"wind_speed\", \"wind_direction\", \"both\"], \"Columns      = wind_speed, wind_direction or both\"\n",
    "    assert speed_height in [\"10\", \"100\", \"both\"],               \"Speed height = 10, 100 or both\"\n",
    "\n",
    "    # Find the speed speed and the wind direction\n",
    "    for d in datasets:\n",
    "\n",
    "        # Computing speed at 10 meters from th ground\n",
    "        if speed_height in [\"10\", \"both\"]:\n",
    "            w_u_10 = d[\"U10\"].to_numpy()\n",
    "            w_v_10 = d[\"V10\"].to_numpy()\n",
    "\n",
    "            if columns in [\"wind_speed\", \"both\"]:\n",
    "                d[\"WS10\"] = np.sqrt(np.square(w_u_10) + np.square(w_v_10))\n",
    "            if columns in [\"wind_direction\", \"both\"]:\n",
    "                d[\"WS10_angle\"] = np.arctan2(w_v_10, w_u_10)\n",
    "\n",
    "        # Computing speed at 100 meters from th ground\n",
    "        if speed_height in [\"100\", \"both\"]:\n",
    "            w_u_100 = d[\"U100\"].to_numpy()\n",
    "            w_v_100 = d[\"V100\"].to_numpy()\n",
    "\n",
    "            if columns in [\"wind_speed\", \"both\"]:\n",
    "                d[\"WS100\"] = np.sqrt(np.square(w_u_100) + np.square(w_v_100))\n",
    "            if columns in [\"wind_direction\", \"both\"]:\n",
    "                d[\"WS100_angle\"] = np.arctan2(w_v_100, w_u_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd96462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADER -- \n",
    "#\n",
    "class dataLoader():\n",
    "    \n",
    "    # Initialization of the loader\n",
    "    def __init__(self, datasets_X, datasets_Y):\n",
    "\n",
    "        # Stores the original, transformed and final datasets\n",
    "        self.original_datasets_X    = datasets_X\n",
    "        self.original_datasets_Y    = datasets_Y\n",
    "        self.transformed_datasets_X = datasets_X\n",
    "        self.transformed_datasets_Y = datasets_Y\n",
    "        self.final_dataset_X        = None\n",
    "        self.final_dataset_Y        = None\n",
    "\n",
    "        # Used to know if datasets have been combined or not\n",
    "        self.isCombined = None\n",
    "\n",
    "    # Used to display the head of the transformed dataset (first set)\n",
    "    def showHeadTransformed(self):\n",
    "        section(\"Dataset - X - Transformed\")\n",
    "        print(self.transformed_datasets_X[0].head())\n",
    "        section(\"Dataset - Y - Transformed\")\n",
    "        print(self.transformed_datasets_Y[0].head())\n",
    "\n",
    "    # Used to split the final dataset into a train and test set (In test set, values for y are equal to -1)\n",
    "    def splitTrainTest(self, save = False, save_dir = \"new_data\"):\n",
    "\n",
    "        # Security\n",
    "        assert self.isCombined != None, \"You must first use self.finalize\"\n",
    "\n",
    "        # Case 1 - Datasets have been combined all together\n",
    "        if self.isCombined == True:\n",
    "            X_train = self.final_dataset_X[self.final_dataset_Y['TARGETVAR'] != -1]\n",
    "            Y_train = self.final_dataset_Y[self.final_dataset_Y['TARGETVAR'] != -1]\n",
    "            X_test  = self.final_dataset_X[self.final_dataset_Y['TARGETVAR'] == -1]\n",
    "            Y_test  = self.final_dataset_Y[self.final_dataset_Y['TARGETVAR'] == -1] # Not useful, I know !\n",
    "\n",
    "        # Case 2 - Datasets are still separated\n",
    "        if self.isCombined == False:\n",
    "            \n",
    "            X_train, Y_train, X_test, Y_test = list(), list(), list(), list()\n",
    "\n",
    "            # Looping over all the small datasets\n",
    "            for x, y in zip(self.final_dataset_X, self.final_dataset_Y):\n",
    "                X_train.append(x[y['TARGETVAR'] != -1])\n",
    "                Y_train.append(y[y['TARGETVAR'] != -1])\n",
    "                X_test.append(x[y['TARGETVAR'] == -1])\n",
    "                Y_test.append(y[y['TARGETVAR'] == -1])\n",
    "\n",
    "        # Be careful with the order\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "        \n",
    "    # Used to perfom final operation on dataset (Combining everything or storing them separately)\n",
    "    def finalization(self, dataset_type = \"combined\"):\n",
    "\n",
    "        # Security\n",
    "        assert dataset_type in [\"combined\", \"separated\"], \"The final dataset can either be of type combined or separated\"\n",
    "\n",
    "        # Case 1 - Combining into one big dataset\n",
    "        if dataset_type == \"combined\":\n",
    "            self.final_dataset_X = pd.concat(self.transformed_datasets_X)\n",
    "            self.final_dataset_Y = pd.concat(self.transformed_datasets_Y)\n",
    "            self.isCombined = True\n",
    "\n",
    "        # Case 2 - Separated datasets\n",
    "        else:\n",
    "            self.final_dataset_X = self.transformed_datasets_X\n",
    "            self.final_dataset_Y = self.transformed_datasets_Y\n",
    "            self.isCombined = False\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    #                                                               PIPELINE\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, useMeanVariance   = True,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24 * 7,\n",
    "                       useZonal          = True,  var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                       usePastTime       = True,  var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON   = 3,\n",
    "                       useNormalize      = True,  var_NORM = [\"U10\", \"V10\", \"U100\", \"V100\"], norm_type = \"max_abs\", data_type = \"column\",\n",
    "                       useSpeedNorm      = True,  SpeedNorm_height = \"both\",\n",
    "                       useSpeedDirection = True,  SpeedDir_height  = \"both\",\n",
    "                       removing          = False, var_removed      = [\"U10\", \"V10\", \"U100\", \"V100\"]):\n",
    "\n",
    "        # Copying original dataset\n",
    "        dX = copy.deepcopy(self.original_datasets_X)\n",
    "        dY = copy.deepcopy(self.original_datasets_Y)\n",
    "\n",
    "        # Applying the different transformations\n",
    "        if useNormalize:\n",
    "            normalize(dX, variables = var_NORM, norm_type = norm_type, data_type = data_type)\n",
    "        if useSpeedNorm:\n",
    "            wind_comp(dX, columns = \"wind_speed\",     speed_height = SpeedNorm_height)\n",
    "        if useSpeedDirection:\n",
    "            wind_comp(dX, columns = \"wind_direction\", speed_height = SpeedDir_height)\n",
    "        if useMeanVariance:\n",
    "            computeMeanVariance(dX, variables = var_MV, window = window_MV, variance = variance_MV)\n",
    "        if useZonal:\n",
    "            computeZonalValue(dX, variables = var_ZON, variance = variance_ZON)\n",
    "        if usePastTime:\n",
    "            addPastTime(dX, variables = var_PT, window = window_ZON)\n",
    "        if removing:\n",
    "            remove(dX, variables = var_removed)\n",
    "        \n",
    "        # Updating dataset\n",
    "        self.transformed_datasets_X = dX\n",
    "        self.transformed_datasets_Y = dY\n",
    "\n",
    "        # Making sure one has to finalize again\n",
    "        self.isCombined = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- CORRELATION MATRIX -- \n",
    "#\n",
    "# Define which correlation matrix to compute\n",
    "nb_correlation = 1\n",
    "\n",
    "# Used to plot correlation matrix\n",
    "def plotCorrelationMatrix(loader, treshold = 0.3, color = \"YlGnBu\", number = 1):\n",
    "\n",
    "    # Finalization of the loader\n",
    "    loader.finalization(dataset_type = \"combined\")\n",
    "    \n",
    "    # Retreives the train and test set (in Pandas frame)\n",
    "    data_X, _, _, _ = loader.splitTrainTest()\n",
    "\n",
    "    # Plotting correlation matrix, removing low values, changing plot color\n",
    "    corr             = data_X.corr()\n",
    "    corr[np.abs(corr) < treshold] = 0\n",
    "    sns.set(rc={'figure.figsize':(25, 20)})\n",
    "    sns.heatmap(corr, cmap = color, annot = True)\n",
    "    plt.savefig(f\"graphs/correlation/correlation_matrix_{number}.png\")\n",
    "\n",
    "# Initialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Plotting\n",
    "if nb_correlation == 1:\n",
    "    loader.pipeline(norm_type = \"max_abs\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 1)\n",
    "elif nb_correlation == 2:\n",
    "    loader.pipeline(norm_type = \"standard\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 2)\n",
    "elif nb_correlation == 3:\n",
    "    loader.pipeline(norm_type = \"robust\", data_type = \"all\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 3)\n",
    "elif nb_correlation == 4:\n",
    "    loader.pipeline(norm_type = \"max_abs\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 4)\n",
    "elif nb_correlation == 5:\n",
    "    loader.pipeline(norm_type = \"standard\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 5)\n",
    "else:\n",
    "    loader.pipeline(norm_type = \"robust\", data_type = \"column\")\n",
    "    plotCorrelationMatrix(loader, treshold = 0.3, number = 6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53e15ed",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Dataset - Generation\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to generate and store all the different datasets that will be tested by the different methods:\n",
    "    <ol>\n",
    "        <li style=\"margin-bottom:10px\">MeanVariance : window = 3, window = 12, window = 24</li>\n",
    "        <li style=\"margin-bottom:10px\">ZonalMean</li>\n",
    "        <li style=\"margin-bottom:10px\">PastTime     : window = 1, window = 2,  window = 3</li>\n",
    "        <li style=\"margin-bottom:10px\">SpeedNorm</li>\n",
    "        <li style=\"margin-bottom:10px\">SpeedDir</li>\n",
    "    </ol> \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53870b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which datasets will be compared to one another\n",
    "dataset_choice = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Define the type of dataset (\"combined\" or \"separated\")\n",
    "dt = \"combined\"\n",
    "\n",
    "# Define which zone you want the dataset from (only works if dt = \"seprated\")\n",
    "zone_id = 1 if dt == \"separated\" else 0\n",
    "\n",
    "# Normalization parameters\n",
    "norm_parameters = [\"standard\", \"all\"]\n",
    "\n",
    "# Define the different window tested by the MeanVariance\n",
    "window_MV = [3, 12, 24]\n",
    "\n",
    "# Define the different window tested by the PastTime\n",
    "window_PT = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ea381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TEMPLATE --\n",
    "\"\"\"\n",
    "loader.pipeline(useMeanVariance    = True,  var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24 * 7,\n",
    "                useZonal           = True,  var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                usePastTime        = True,  var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON   = 3,\n",
    "                useNormalize       = True,  var_NORM = [\"U10\", \"V10\", \"U100\", \"V100\"], norm_type = \"max_abs\", data_type = \"column\",\n",
    "                useSpeedNorm       = True,  SpeedNorm_height = \"both\",\n",
    "                useSpeedDirection  = True,  SpeedDir_height  = \"both\",\n",
    "                removing           = False, var_removed      = [\"U10\", \"V10\", \"U100\", \"V100\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "728a4aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating : ...\n",
      "Generating : Done\n",
      "Number of generated datasets: 10\n"
     ]
    }
   ],
   "source": [
    "# -- GENERATION OF THE DATASETS --\n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X, datasets_X_submit, datasets_Y, datasets_Y_submit = list(), list(), list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Retrieving the index of the zone considered\n",
    "index_zone = zone_id - 1\n",
    "\n",
    "# 0 - Originals\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = False,\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization(dataset_type = dt)\n",
    "\n",
    "# Creation of datasets\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "# Adding all the datasets\n",
    "datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "# 1 - MeanVariance\n",
    "if 1 in dataset_choice:\n",
    "    for w in window_MV:\n",
    "        loader.pipeline(useMeanVariance    = True, var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = w,\n",
    "                        useZonal           = False,\n",
    "                        usePastTime        = False,\n",
    "                        useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                        useSpeedNorm       = False,\n",
    "                        useSpeedDirection  = False,\n",
    "                        removing           = False)\n",
    "        loader.finalization(dataset_type = dt)\n",
    "\n",
    "        # Creation of datasets\n",
    "        X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "        # Adding all the datasets\n",
    "        datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "        datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "        datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "        datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "# 2 - ZonalMean\n",
    "if 2 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,\n",
    "                    useZonal           = True, var_ZON  = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_ZON = True,\n",
    "                    usePastTime        = False,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = False,\n",
    "                    useSpeedDirection  = False,\n",
    "                    removing           = False)\n",
    "    loader.finalization(dataset_type = dt)\n",
    "\n",
    "    # Creation of datasets\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    # Adding all the datasets\n",
    "    datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "    datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "    datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "\n",
    "# 3 - PastTime\n",
    "if 3 in dataset_choice:\n",
    "    for w in window_PT:\n",
    "        loader.pipeline(useMeanVariance    = False,\n",
    "                        useZonal           = False,\n",
    "                        usePastTime        = True, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = w,\n",
    "                        useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                        useSpeedNorm       = False,\n",
    "                        useSpeedDirection  = False,\n",
    "                        removing           = False)\n",
    "        loader.finalization(dataset_type = dt)\n",
    "\n",
    "        # Creation of datasets\n",
    "        X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "        # Adding all the datasets\n",
    "        datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "        datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "        datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "        datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "\n",
    "# 4 - SpeedNorm\n",
    "if 4 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,\n",
    "                    useZonal           = False,\n",
    "                    usePastTime        = False,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = True, SpeedNorm_height = \"both\",\n",
    "                    useSpeedDirection  = False,\n",
    "                    removing           = False)\n",
    "    loader.finalization(dataset_type = dt)\n",
    "\n",
    "    # Creation of datasets\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    # Adding all the datasets\n",
    "    datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "    datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "    datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "\n",
    "# 5 - SpeedDir\n",
    "if 5 in dataset_choice:\n",
    "    loader.pipeline(useMeanVariance    = False,\n",
    "                    useZonal           = False,\n",
    "                    usePastTime        = False,\n",
    "                    useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                    useSpeedNorm       = False,\n",
    "                    useSpeedDirection  = True, SpeedDir_height  = \"both\",\n",
    "                    removing           = False)\n",
    "    loader.finalization(dataset_type = dt)\n",
    "\n",
    "    # Creation of datasets\n",
    "    X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "\n",
    "    # Adding all the datasets\n",
    "    datasets_X.append(       X[index_zone]        if dt == \"separated\" else X)\n",
    "    datasets_Y.append(       Y[index_zone]        if dt == \"separated\" else Y)\n",
    "    datasets_X_submit.append(submit_X[index_zone] if dt == \"separated\" else submit_X) \n",
    "    datasets_Y_submit.append(submit_Y[index_zone] if dt == \"separated\" else submit_Y)\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(\"Generating : Done\")\n",
    "print(f\"Number of generated datasets: {len(datasets_X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a06df83",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model - Pre-Classifier\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Trained a model to pre-classify the data (wether or not, power is created with wind conditions);</li>\n",
    "        <li style=\"margin-bottom:10px\">Observe a custom class \"ModelEnsemble\" which allow to create a model resulting from the combination of the pre-classifier and a trained model.</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ENSEMBLE MODEL --\n",
    "#\n",
    "# The goal of this class is to create our own predict function which is composed of 2 main steps:\n",
    "# - The pre-classifier's determines whether or not the wind is sufficiently high to have a power creation\n",
    "# - The model which predicts the power creation\n",
    "class ModelEnsemble():\n",
    "\n",
    "    # Initialization of the ensemble model\n",
    "    def __init__(self, model_prec_classifier, model_trained):\n",
    "        self.pre_classifier = model_prec_classifier\n",
    "        self.trained        = model_trained \n",
    "    \n",
    "    # Used to compute predictions\n",
    "    def predict(self, x, predict_treshold = 0.95):\n",
    "\n",
    "        # 1 - Determining if there is power or not \n",
    "        PC_results  = self.pre_classifier.predict_proba(x)\n",
    "\n",
    "        # 2 - Power predictions\n",
    "        MOD_results = self.trained.predict(x)\n",
    "\n",
    "        # 3 - Replacing predictions with pre-classifier results \n",
    "        for i, r in enumerate(PC_results):\n",
    "            MOD_results[i] = 0 if r[0] > predict_treshold else MOD_results[i]\n",
    "\n",
    "        return MOD_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11846a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PRE-CLASSIFIER'S DATASET --\n",
    "# \n",
    "# Creation of the special dataset for training the pre-classifier\n",
    "dataset_X_preclassifier = copy.deepcopy(datasets_X[0])\n",
    "dataset_Y_preclassifier = copy.deepcopy(datasets_Y[0])\n",
    "\n",
    "# Transforming into binary classification problem (0 = no power, 1 = power to predict)\n",
    "dataset_Y_preclassifier[dataset_Y_preclassifier[\"TARGETVAR\"] != 0] = 1\n",
    "dataset_X_preclassifier                                            = dataset_X_preclassifier.to_numpy()\n",
    "dataset_Y_preclassifier                                            = dataset_Y_preclassifier[\"TARGETVAR\"].to_numpy()\n",
    "\n",
    "# Retreiving train and test sets\n",
    "X_PRE_train, X_PRE_test, y_PRE_train, y_PRE_test = train_test_split(dataset_X_preclassifier, dataset_Y_preclassifier, test_size = 0.3, random_state = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING OF THE PRE-CLASSIFIER -- \n",
    "#\n",
    "# Definition of the parameters that will be tested\n",
    "GS_param_dt  = {'max_depth'   : [i for i in range(7, 13)]}\n",
    "\n",
    "# Initialization of the model\n",
    "model_pre_classifier = GridSearchCV(tree.DecisionTreeClassifier(), GS_param_dt)\n",
    "\n",
    "# Finding the best parameter\n",
    "model_pre_classifier.fit(X_PRE_train, y_PRE_train)\n",
    "\n",
    "# Computing final accuracy \n",
    "accuracy_pre_classifier = model_pre_classifier.score(X_PRE_test, y_PRE_test)\n",
    "\n",
    "# Display information over terminal (1)\n",
    "section(\"Results\")\n",
    "print(f\"Pre classifier's accuracy [%] : {accuracy_pre_classifier * 100}\")\n",
    "print(model_pre_classifier.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1cb5f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model - Training | Testing | Plotting results per Zone\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Find functions to plot easily compare accuracy results of a method against each dataset.</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b153cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ERROR COMPUTATION --\n",
    "#\n",
    "# Found from : https://github.com/smazzanti\n",
    "#\n",
    "def _yield_pairs(y_true, num_rounds):\n",
    "  \"\"\"\n",
    "  Returns pairs of valid indices. Indices must belong to observations having different values.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true     : array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  num_rounds : int or string. If integer, number of random pairs of observations to return. \n",
    "               If string, 'exact', all possible pairs of observations will be returned.\n",
    "  \n",
    "  Yields:\n",
    "  -------\n",
    "  i, j: tuple of int of shape (2,). Indices referred to a pair of samples.\n",
    "  \"\"\"\n",
    "  if num_rounds == 'exact':\n",
    "    for i in range(len(y_true)):\n",
    "      for j in np.where((y_true != y_true[i]) & (np.arange(len(y_true)) > i))[0]:\n",
    "        yield i, j     \n",
    "  else:\n",
    "    for r in range(num_rounds):\n",
    "      i = np.random.choice(range(len(y_true)))\n",
    "      j = np.random.choice(np.where(y_true != y_true[i])[0])\n",
    "      yield i, j\n",
    "\n",
    "def regression_roc_auc_score(y_true, y_pred, num_rounds = 10000):\n",
    "  \"\"\"\n",
    "  Computes Regression-ROC-AUC-score.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true     : array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  y_pred     : array-like of shape (n_samples,). Target scores.\n",
    "  num_rounds : int or string. If integer, number of random pairs of observations. \n",
    "               If string, 'exact', all possible pairs of observations will be evaluated.\n",
    "  \n",
    "  Returns:\n",
    "  -------\n",
    "  rroc: float. Regression-ROC-AUC-score.\n",
    "  \"\"\"\n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "  num_pairs     = 0\n",
    "  num_same_sign = 0\n",
    "  \n",
    "  for i, j in _yield_pairs(y_true, num_rounds):\n",
    "    diff_true  = y_true[i] - y_true[j]\n",
    "    diff_score = y_pred[i] - y_pred[j]\n",
    "\n",
    "    if diff_true * diff_score > 0:\n",
    "      num_same_sign += 1\n",
    "    elif diff_score == 0:\n",
    "      num_same_sign += .5\n",
    "    num_pairs += 1\n",
    "      \n",
    "  return num_same_sign / num_pairs\n",
    "\n",
    "def computeError(n_y_true, n_y_pred):\n",
    "    \"\"\"\n",
    "    Compute the error to evaluate the performance of the model \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    n_y_true: list of np.array\n",
    "              Ground truth (correct) target values.\n",
    "\n",
    "\n",
    "    n_y_pred: list of np.array \n",
    "              Estimated target values.\n",
    "    \n",
    "   \n",
    "    \"\"\"\n",
    "    mae, rmse, mdae, r2, auc = [], [], [], [], []\n",
    "\n",
    "    for y_true, y_pred in zip(n_y_true, n_y_pred):\n",
    "        mae.append(mean_absolute_error(y_true, y_pred))\n",
    "        rmse.append(mean_squared_error(y_true, y_pred, squared = False))\n",
    "        mdae.append(median_absolute_error(y_true, y_pred))\n",
    "\n",
    "        r2.append(r2_score(y_true, y_pred))\n",
    "        auc.append(regression_roc_auc_score(y_true, y_pred, num_rounds = 1000))\n",
    "\n",
    "    return mae, rmse, mdae, r2, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a3b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to compute a model's accuracy against different datasets\n",
    "def modelTesting(datasets_X, datasets_y, model, test_size = 0.3, random_state = 69):\n",
    "    \n",
    "    # Contains mean accuracy of the model against each dataset\n",
    "    accuracy_train, accuracy_test, y_true, y_pred = list(), list(), list(), list()\n",
    "\n",
    "    # Looping over whole the different datasets\n",
    "    for X, y in zip(datasets_X, datasets_y):\n",
    "        \n",
    "        # Final conversion (Numpy and retrieving targets)\n",
    "        X = X.to_numpy()\n",
    "        y = y[[\"TARGETVAR\"]].to_numpy().ravel()\n",
    "\n",
    "        # Retrieving datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "        # Fitting the model on current split\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Prediction \n",
    "        y_pred.append(model.predict(X_test))\n",
    "        y_true.append(y_test)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy_train.append(model.score(X_train, y_train))\n",
    "        accuracy_test.append(model.score(X_test, y_test))\n",
    "\n",
    "    return accuracy_train, accuracy_test, y_pred, y_true \n",
    "\n",
    "# Used to determine the best parameter and the associated dataset\n",
    "def computeBest (parameters, acc_train, acc_test, y_pred, y_true):\n",
    "\n",
    "    # Used to store the best results\n",
    "    acc_test_best, acc_train_best = [], []\n",
    "    y_pred_best,  y_true_best     = [], []\n",
    "    param_best                    = []\n",
    "\n",
    "    # Looping over accuracies to find best results\n",
    "    for a1, a2, y1, y2 in zip(acc_train, acc_test, y_pred, y_true):\n",
    "\n",
    "        # Finding best test accuracy\n",
    "        max_value = max(a2)\n",
    "        max_index = a2.index(max_value)\n",
    "\n",
    "        # Adding results\n",
    "        acc_test_best.append(max_value)\n",
    "        acc_train_best.append(a1[max_index])\n",
    "        y_pred_best.append(y1[max_index])\n",
    "        y_true_best.append(y2[max_index])\n",
    "        param_best.append(parameters[max_index])\n",
    "\n",
    "    return acc_test_best, acc_train_best, y_pred_best, y_true_best, param_best\n",
    "\n",
    "# Used to compare the accuracy of a model against each dataset\n",
    "def modelPlotResults(parameters, acc_train, acc_test, y_pred, y_true, \n",
    "                     xlabel, param_name, fontsize = 15, save_path = \"graphs/\", evolution_param = True):\n",
    "\n",
    "    # Chaging overall font scale\n",
    "    sns.set(font_scale = 1.1)\n",
    "    \n",
    "    # In some cases, like for linear regression, there is no parameter to make evoluate\n",
    "    if evolution_param:\n",
    "\n",
    "        # 1 - Evolution of the test accuracy\n",
    "        plt.figure(figsize = (15, 15))\n",
    "\n",
    "        # Plotting evolution curve for a specific dataset with varying parameter value\n",
    "        for i, a in enumerate(acc_test):\n",
    "            plt.plot(parameters, [a_i * 100 for a_i in a], label = f\"D{i}\", linewidth = 4)\n",
    "        \n",
    "        plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "        plt.ylabel(\"Accuracy [%]\", fontsize = fontsize)\n",
    "        plt.xlabel(xlabel, fontsize = fontsize)\n",
    "        plt.savefig(f\"{save_path}_1.png\")\n",
    "        plt.show()\n",
    "   \n",
    "        acc_test_best, acc_train_best, y_pred_best, y_true_best, k_best = computeBest(parameters, \n",
    "                                                                                      acc_train, \n",
    "                                                                                      acc_test, \n",
    "                                                                                      y_pred, \n",
    "                                                                                      y_true)\n",
    "                                      \n",
    "        # Definition of the xlabel for the bar plot\n",
    "        x_ax_labels_1 = [f\"D{i} - {param_name} = {k_best[i]}\" for i in range(len(acc_train))]\n",
    "        x_ax_labels_2 = [f\"D{i} - {param_name} = {k_best[i]}\" for i in range (len(y_pred))]\n",
    "\n",
    "    else:\n",
    "        x_ax_labels_1 = [f\"D{i}\" for i in range(len(acc_train))]\n",
    "        x_ax_labels_2 = [f\"D{i}\" for i in range (len(y_pred))]\n",
    "        acc_test_best, acc_train_best = acc_test, acc_train\n",
    "        y_pred_best, y_true_best      = y_pred, y_true \n",
    "\n",
    "    # 2 - Bar plot of accuracy \n",
    "    index = [i for i in range(len(acc_train))]\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize = (20, 7))\n",
    "    plt.bar([i - 0.2 for i in index], [a_i * 100 for a_i in acc_train_best], 0.4, label = \"Train\")\n",
    "    plt.bar([i + 0.2 for i in index], [a_i * 100 for a_i in acc_test_best ], 0.4, label = \"Test\")\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_1)\n",
    "    plt.ylabel(\"Accuracy [%]\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_2.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 3 - Bar plot of different errors and accuracy measurements\n",
    "    mae, rmse, mdae, r2, auc = [], [], [], [], []\n",
    "    mae, rmse, mdae, r2, auc = computeError(y_true_best, y_pred_best)\n",
    "  \n",
    "    # Used to make x-axis\n",
    "    index = [i for i in range(len(y_pred))]\n",
    "    \n",
    "    # Plotting the results\n",
    "    plt.figure(figsize = (20, 12))\n",
    "    plt.subplot(211)\n",
    "    plt.bar([i - 0.2 for i in index], [mae_i *100 for mae_i in mae],     0.2, label = \"Mean Absolute Error\")\n",
    "    plt.bar([i   for i in index],     [rmse_i *100  for rmse_i in rmse], 0.2, label = \"Root Mean Squared Error\")\n",
    "    plt.bar([i + 0.2 for i in index], [mdae_i  *100 for mdae_i in mdae], 0.2, label = \"Median Absolute Error\")\n",
    "    plt.ylabel(\"Error [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_2)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.subplot(212)\n",
    "    plt.bar([i - 0.1 for i in index], [r2_i * 100 for r2_i in r2],    0.2, label = \"R2 Score\")\n",
    "    plt.bar([i + 0.1 for i in index], [auc_i * 100 for auc_i in auc], 0.2, label = \"AUC\")\n",
    "    plt.ylabel(\"Measurement [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, x_ax_labels_2)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_Error.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Used to compare the accuracy of a model against each others (adaptation for complex models)\n",
    "def modelPlotResultsComplex(y_pred, y_true, xlabels, fontsize = 15, save_path = \"graphs/\"):\n",
    "\n",
    "    # Security\n",
    "    assert len(y_pred) == len(y_true),  f\"Number of predictions = {len(y_pred)},  Number of exact measurements = {len(y_true)}\"\n",
    "    assert len(y_pred) == len(xlabels), f\"Number of predictions = {len(y_pred)}, Number of labels             = {len(xlabels)}\"\n",
    "\n",
    "    # Stores the differents errors and accuracy measurements\n",
    "    mae, rmse, mdae, r2, auc = list(), list(), list(), list(), list()\n",
    "\n",
    "    # Computing everything\n",
    "    mae, rmse, mdae, r2, auc = computeError(y_true, y_pred)\n",
    "\n",
    "    # Used to make x-axis\n",
    "    index = [i for i in range(len(y_pred))]\n",
    "    \n",
    "    # Plotting the results\n",
    "    sns.set(font_scale = 1.1)\n",
    "    plt.figure(figsize = (20, 12))\n",
    "    plt.subplot(211)\n",
    "    plt.bar([i - 0.2 for i in index], [mae_i *100 for mae_i in mae]    , 0.2, label = \"Mean Absolute Error\")\n",
    "    plt.bar([i   for i in index],     [rmse_i *100  for rmse_i in rmse], 0.2, label = \"Root Mean Squared Error\")\n",
    "    plt.bar([i + 0.2 for i in index], [mdae_i  *100 for mdae_i in mdae], 0.2, label = \"Median Absolute Error\")\n",
    "    plt.ylabel(\"Error [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, xlabels)\n",
    "    plt.legend(loc = \"upper left\", fontsize = fontsize)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar([i - 0.1 for i in index], [r2_i * 100 for r2_i in r2],    0.2, label = \"R2 Score\")\n",
    "    plt.bar([i + 0.1 for i in index], [auc_i * 100 for auc_i in auc], 0.2, label = \"AUC\")\n",
    "    plt.ylabel(\"Measurement [%] \", fontsize = fontsize)\n",
    "    plt.xticks(index, xlabels)\n",
    "    plt.legend(loc=\"upper left\", fontsize = fontsize)\n",
    "    plt.savefig(f\"{save_path}_Error.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a90924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- OTHERS --\n",
    "#\n",
    "# Used to display a simple progress bar while training for 1 epoch\n",
    "def progressBar(loss_training, loss_test, r2_test, estimated_time_epoch, nb_epoch_left, percent, width = 40):\n",
    "\n",
    "    # Setting up the useful information\n",
    "    left          = width * percent // 100\n",
    "    right         = width - left\n",
    "    tags          = \"#\" * int(left)\n",
    "    spaces        = \" \" * int(right)\n",
    "    percents      = f\"{percent:.2f} %\"\n",
    "    loss_training = f\"{loss_training * 1:.4f}\"\n",
    "    loss_test     = f\"{loss_test * 1:.4f}\"\n",
    "    r2_test       = f\"{r2_test * 100 * 1:.4f}\"\n",
    "\n",
    "    # Computing timings\n",
    "    estimated_time_total = f\"{nb_epoch_left * estimated_time_epoch:.2f} s\"\n",
    "\n",
    "    # Creation of the string\n",
    "    bar = f\"[{tags}{spaces}] - {percents}  | Loss (Training) = {loss_training} | Loss (Test) = {loss_test} | R2 Metric [%] = {r2_test} | Time left : {estimated_time_total} |\"\n",
    "\n",
    "    # Displaying the progress bar\n",
    "    print(bar, end = \"\\r\", flush = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d4e8035",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 187px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Linear Regression (Example)</p>\n",
    "<hr style=\"color:#c6cde1; width: 187px;\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9798ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING -- \n",
    "#\n",
    "# Initialization of the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Computing accuracies\n",
    "lr_accuracy_train, lr_accuracy_test, lr_y_pred, lr_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821a18bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults([], lr_accuracy_train, lr_accuracy_test, lr_y_pred, lr_y_true, \n",
    "                 xlabel = \"Slope\", param_name = \"Slope\", fontsize = 10, \n",
    "                 save_path = \"graphs/lr/lr\", evolution_param = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "741bdf3e",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1; width: 105px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Regression tree </p>\n",
    "<hr style=\"color:#c6cde1; width: 105px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec680528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "dt_param = np.linspace(5, 20, 15, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "dt_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "dt_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "dt_y_pred = [[] for i in range(len(datasets_X))]\n",
    "dt_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in dt_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = tree.DecisionTreeRegressor(max_depth = depth, random_state=4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        dt_accuracy_train[i].append(acc_1)\n",
    "        dt_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        dt_y_pred[i].append(y_pred)\n",
    "        dt_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e996b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(dt_param, dt_accuracy_train, dt_accuracy_test, dt_y_pred, dt_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, evolution_param = True,\n",
    "                 param_name = \"Depth\", save_path = \"graphs/dt/dt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">K-Neighbors-Regressor</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "k_param = np.arange(1, 100, 10, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "knn_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "knn_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "knn_y_pred = [[] for i in range(len(datasets_X))]\n",
    "knn_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for k in k_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = KNeighborsRegressor(n_neighbors = k)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        knn_accuracy_train[i].append(acc_1)\n",
    "        knn_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        knn_y_pred[i].append(y_pred)\n",
    "        knn_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(k_param, knn_accuracy_train, knn_accuracy_test, knn_y_pred, knn_y_true,\n",
    "                 xlabel = \"Number of k Neighbors - $k$ [-]\", fontsize = 10, \n",
    "                 param_name = \"knn\", save_path = \"graphs/knn/knn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 225px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Linear Support Vector Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 225px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING -- \n",
    "#\n",
    "# Parameters to test for Grid Search\n",
    "C_param = np.linspace(0.001, 1, num=20)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "svr_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "svr_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "svr_y_pred = [[] for i in range(len(datasets_X))]\n",
    "svr_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for c in C_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = LinearSVR(random_state=0, dual = False, loss = \"squared_epsilon_insensitive\", C = c, epsilon = 0.001)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        svr_accuracy_train[i].append(acc_1)\n",
    "        svr_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        svr_y_pred[i].append(y_pred)\n",
    "        svr_y_true[i].append(y_true)\n",
    "\n",
    "# Rounding values of alpha for better display\n",
    "C_param = [round(item, 3) for item in C_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(C_param, svr_accuracy_train, svr_accuracy_test, svr_y_pred, svr_y_true,\n",
    "                 xlabel = \"Regularization parameter - $C$ [-]\", fontsize = 10, evolution_param = True,\n",
    "                 param_name = \"C\", save_path = \"graphs/svr/svr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da56ff",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 115px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Ridge Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 115px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "alpha_param = np.linspace(40, 0.01, 50)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "rr_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "rr_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "rr_y_pred = [[] for i in range(len(datasets_X))]\n",
    "rr_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for alpha in alpha_param:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = Ridge(alpha = alpha)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        rr_accuracy_train[i].append(acc_1)\n",
    "        rr_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        rr_y_pred[i].append(y_pred)\n",
    "        rr_y_true[i].append(y_true)\n",
    "\n",
    "# Rounding values of alpha for better display\n",
    "alpha_param = [round(item, 2) for item in alpha_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(alpha_param, rr_accuracy_train, rr_accuracy_test, rr_y_pred, rr_y_true,\n",
    "                 xlabel = \"Penalization - alpha [-]\", fontsize = 10, \n",
    "                 param_name = \"alpha\", save_path = \"graphs/rr/rr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10f146",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 102px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Random Forest</p>\n",
    "<hr style=\"color:#c6cde1; width: 102px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4495ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "rf_max_depth = np.linspace(10, 30, 2, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "rf_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "rf_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "rf_y_pred = [[] for i in range(len(datasets_X))]\n",
    "rf_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in rf_max_depth:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = RandomForestRegressor(max_depth = depth, n_estimators = 20, n_jobs = 4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        rf_accuracy_train[i].append(acc_1)\n",
    "        rf_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        rf_y_pred[i].append(y_pred)\n",
    "        rf_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(rf_max_depth, rf_accuracy_train, rf_accuracy_test, rf_y_pred, rf_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, \n",
    "                 param_name = \"Depth\", save_path = \"graphs/rf/rf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b76b278a",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Extra Trees Regression</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Definition of the parameters to be tested\n",
    "et_max_depth = np.linspace(10, 30, 2, dtype = int)\n",
    "\n",
    "# Stores the accuracy of the training and testing\n",
    "et_accuracy_train = [[] for i in range(len(datasets_X))]\n",
    "et_accuracy_test  = [[] for i in range(len(datasets_X))]\n",
    "et_y_pred = [[] for i in range(len(datasets_X))]\n",
    "et_y_true = [[] for i in range(len(datasets_X))]\n",
    "\n",
    "for depth in et_max_depth:\n",
    "\n",
    "    # Initialization of the model\n",
    "    model = ExtraTreesRegressor(max_depth = depth, n_estimators = 100, n_jobs = 4)\n",
    "\n",
    "    # Computing accuracies on all the datasets\n",
    "    acc_train, acc_test, n_y_pred, n_y_true = modelTesting(datasets_X, datasets_Y, model, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    # Adding the results\n",
    "    for i, acc_1, acc_2 in zip(range(len(acc_train)), acc_train, acc_test):\n",
    "        et_accuracy_train[i].append(acc_1)\n",
    "        et_accuracy_test[i].append(acc_2)\n",
    "\n",
    "    for i, y_pred, y_true in zip(range(len(n_y_pred)), n_y_pred, n_y_true):\n",
    "        et_y_pred[i].append(y_pred)\n",
    "        et_y_true[i].append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(et_max_depth, et_accuracy_train, et_accuracy_test, et_y_pred, et_y_true,\n",
    "                 xlabel = \"Depth of the tree - $d$ [-]\", fontsize = 10, \n",
    "                 param_name = \"Depth\", save_path = \"graphs/et/et\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da56ff",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">\n",
    "<p style=\"color:#c6cde1;\">Multi-Layer-Perceptron</p>\n",
    "<hr style=\"color:#c6cde1; width: 155px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS --\n",
    "# \n",
    "# Number of epochs for the training\n",
    "number_epochs = 2\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Batch size\n",
    "bs = 64\n",
    "\n",
    "# Dimensional factor for the NN architecture\n",
    "size_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- NEURAL NETWORK -- \n",
    "class MLP_PowerPrediction(nn.Module):\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, input_size, nn_size = 2):\n",
    "\n",
    "        # Need to call the super to define child functions\n",
    "        super(MLP_PowerPrediction, self).__init__()\n",
    "\n",
    "        # Used to increase simply the size of the network\n",
    "        size_factor = nn_size\n",
    "\n",
    "        # Contains the fully connected layers\n",
    "        self.fullyConnected_1 = nn.Linear(in_features = input_size,       out_features = 16 * size_factor).double()\n",
    "        self.fullyConnected_2 = nn.Linear(in_features = 16 * size_factor, out_features = 32 * size_factor).double()\n",
    "        self.fullyConnected_3 = nn.Linear(in_features = 32 * size_factor, out_features = 32 * size_factor).double()\n",
    "        self.fullyConnected_4 = nn.Linear(in_features = 32 * size_factor, out_features = 16 * size_factor).double()\n",
    "        self.fullyConnected_5 = nn.Linear(in_features = 16 * size_factor, out_features = 1).double()\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def forward(self, x):\n",
    "        x = self.fullyConnected_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fullyConnected_5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATALOADER --\n",
    "class PowerDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "            # Conversion to numpy and double type (needed for torch weight)\n",
    "            X = X.to_numpy().astype(np.double)\n",
    "            y = y[\"TARGETVAR\"].to_numpy().astype(np.double)\n",
    "\n",
    "            # Conversion to torch tensor\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def getDatasets(self):\n",
    "        return self.X, self.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING & TESTING --\n",
    "#\n",
    "# Contains evolution of training and test lost over the epochs for each dataset\n",
    "nn_accuracy_train_total, nn_accuracy_test_total, nn_y_pred_total, nn_y_true_total = list(), list(), list(), list()\n",
    "\n",
    "# Used to compute R2 Metric\n",
    "r2score = R2Score()\n",
    "\n",
    "# Looping over all the datasets\n",
    "for i, dataset_X, dataset_Y in zip(range(len(datasets_X)), datasets_X, datasets_Y):\n",
    "\n",
    "    # Creation of train and test sets\n",
    "    X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(dataset_X, dataset_Y, test_size = 0.3)\n",
    "\n",
    "    # Generation of the datasets\n",
    "    POWER_loader_train   = DataLoader(PowerDataset(X_NN_train, Y_NN_train), batch_size = bs)\n",
    "    X_NN_test, Y_NN_test = PowerDataset(X_NN_test,  Y_NN_test).getDatasets()\n",
    "\n",
    "    # Number of inputs in current datasets\n",
    "    nb_inputs =  len(dataset_X.to_numpy()[0])\n",
    "\n",
    "    # Initalization of the network\n",
    "    model_NN = MLP_PowerPrediction(nb_inputs, nn_size = size_factor) \n",
    "\n",
    "    # ---- Some stuff you don't need to look into ----\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_NN.parameters(), lr = 0.001)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones = [int(number_epochs/2), int(number_epochs * 3/4), int(number_epochs * 7/8)], \n",
    "                                               gamma      = 0.1)\n",
    "\n",
    "    # Used to compute training progression bar (1)\n",
    "    size_train = len(X_NN_train)\n",
    "    epoch_time = 0\n",
    "\n",
    "    # Contains evolution of training and test lost over the epochs\n",
    "    nn_accuracy_train, nn_accuracy_test, nn_y_pred, nn_y_true  = list(), list(), list(), list()\n",
    "\n",
    "    # Display useful information over terminal (0)\n",
    "    section(f\"Neural Network - Training & Testing : Dataset ({i + 1}/{len(datasets_X)})\")\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(number_epochs):\n",
    "\n",
    "        # Used to compute loss\n",
    "        epoch_loss_train  = 0.0\n",
    "        epoch_steps_train = 0\n",
    "        epoch_loss_test   = 0.0\n",
    "        epoch_steps_test  = 0\n",
    "\n",
    "        # Display useful information over terminal (1)\n",
    "        print(\"Epoch : \", epoch + 1, \"/\", number_epochs)\n",
    "\n",
    "        # Used to compute training progression bar (2)\n",
    "        index = bs\n",
    "\n",
    "        # Used to approximate time left for current epoch and in total\n",
    "        start = time.time()\n",
    "\n",
    "        #----------------------\n",
    "        #       Training\n",
    "        #----------------------\n",
    "        # Retreiving a batch of data\n",
    "        for x, y in POWER_loader_train:\n",
    "\n",
    "            # Reseting gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(x)\n",
    "            ytrue = torch.unsqueeze(y, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss = criterion(yhat, ytrue)\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating epoch info ! Would be nice to upgrade it !\n",
    "            epoch_loss_train   += loss.item()\n",
    "            epoch_steps_train  += 1\n",
    "            nb_epoch_left = number_epochs - epoch\n",
    "            percentage    = (index/size_train) * 100 if (index/size_train) <= 1 else 100\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, 0, 0, epoch_time, nb_epoch_left, percentage)\n",
    "            index += bs\n",
    "\n",
    "        # Updating the scheduler to update learning rate !\n",
    "        scheduler.step()\n",
    "\n",
    "        #----------------------\n",
    "        #       Testing\n",
    "        #----------------------\n",
    "        with torch.no_grad():  \n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(X_NN_test)\n",
    "            ytrue = torch.unsqueeze(Y_NN_test, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss_mse = criterion(yhat, ytrue)\n",
    "            loss_r2  = r2score(yhat, ytrue)\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, loss_mse.item(), loss_r2, epoch_time, nb_epoch_left, percentage)\n",
    "\n",
    "        # Updating timing\n",
    "        epoch_time    = time.time() - start\n",
    "\n",
    "        # Updating training and test accuracies\n",
    "        nn_accuracy_train.append(epoch_loss_train/epoch_steps_train)\n",
    "        nn_accuracy_test.append(loss_mse)\n",
    "        nn_y_pred.append(yhat.cpu().detach().numpy())\n",
    "        nn_y_true.append(ytrue.cpu().detach().numpy())\n",
    "\n",
    "        # Just to make sure there is no overlap between progress bar and section\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    # Updating training and test accuracies\n",
    "    nn_accuracy_train_total.append(nn_accuracy_train)\n",
    "    nn_accuracy_test_total.append(nn_accuracy_test)\n",
    "    nn_y_pred_total.append(nn_y_pred)\n",
    "    nn_y_true_total.append(nn_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PLOTTING THE RESULTS --\n",
    "modelPlotResults(np.linspace(1, number_epochs, number_epochs), nn_accuracy_train_total, nn_accuracy_test_total, nn_y_pred_total, nn_y_true_total,\n",
    "                 xlabel = \"Number of epochs [-]\", fontsize = 10, \n",
    "                 param_name = \"Epoch\", save_path = \"graphs/nn/nn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6b1cb5f",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Ensemble Methods : Voting & Stacking Regressors\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will try different ways to gather basic methods to improve the accuracy:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Gather methods with the same accuracy inside a voting or stacking classifier;</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTION --\n",
    "#\n",
    "def combine_methods(ensemble_method, methods_to_gather):\n",
    "    #--------------\n",
    "    # Documentation\n",
    "    #--------------\n",
    "    # - ensemble_method   : a string whose values may be either 'stacking' or 'voting'\n",
    "    #\n",
    "    # - methods_to_gather : A list with the methods to gather inside an ensemble regressor\n",
    "    #\n",
    "    if ensemble_method == 'stacking':\n",
    "        model = StackingRegressor(estimators = methods_to_gather, final_estimator = LinearRegression(), n_jobs = 4)\n",
    "\n",
    "    elif ensemble_method == 'voting':\n",
    "        model = VotingRegressor(methods_to_gather, n_jobs = 4)\n",
    "\n",
    "    return model\n",
    "\n",
    "def pred_combine_methods(dataset_X, dataset_Y, first_model_name = 'RandomForest', ensemble_method  = 'voting', \n",
    "                         parameters = [{'n_estimators': [80], 'max_depth': [50]}], number_folds    = 5,\n",
    "                         random_state = 69):\n",
    "    #--------------\n",
    "    # Documentation\n",
    "    #--------------\n",
    "    # - first_model_name : a string with the name of the tree regressor, can be either \n",
    "    #                      'RandomForest' or 'ExtraTreesRegressor'\n",
    "    # - ensemble_method  : a string whose values may be either 'stacking' or 'voting'\n",
    "    # - parameters       : a list of dictionary with the paramers for the GridSearch\n",
    "    # - number_folds     : an integer indicating the number of folds for the GridSearch\n",
    "    # - random_state     : an integer indacting the seed of random objects\n",
    "    #\n",
    "    # Security\n",
    "    assert first_model_name in [\"RandomForest\", \"ExtraTreesRegressor\"], \"First model = RandomForest or ExtraTreesRegressor\"\n",
    "    assert ensemble_method  in [\"stacking\", \"voting\"],                  \"Ensemble method = voting or stacking\"\n",
    "    \n",
    "    # Displaying information over terminal (1)\n",
    "    print('Progression:...')\n",
    "\n",
    "    # Stores all the results from the training session\n",
    "    best_parameters, y_pred_zones, y_true_zones = list(), list(), list()\n",
    "\n",
    "    # Looping over all the different zones\n",
    "    for zone_ID in range(1, 11):\n",
    "        \n",
    "        # Used to have an idea of simulation time (1)\n",
    "        start = time.time()\n",
    "\n",
    "        # ============= Creation of the sets for the corresponding zone =============\n",
    "        x  =  dataset_X[zone_ID - 1].to_numpy()\n",
    "        y  =  dataset_Y[zone_ID - 1][[\"TARGETVAR\"]].to_numpy().ravel()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = random_state)\n",
    "\n",
    "        # ============== Creation of the combined model (1st layer) ==================\n",
    "        r1 = ExtraTreesRegressor(random_state = random_state) if first_model_name == \"ExtraTrees\" else RandomForestRegressor(random_state = random_state)\n",
    "\n",
    "        # Looking for best tree\n",
    "        r1_best_model = GridSearchCV(r1, parameters, cv = number_folds, refit=True, \n",
    "                                     verbose = 0, n_jobs = 4, scoring = 'r2')\n",
    "        \n",
    "        # Fitting on training data\n",
    "        r1_best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Retreiving best parameters\n",
    "        best_parameters.append(r1_best_model.best_params_)\n",
    "\n",
    "        # =========== Creation of the combined model (2nd layer & Training) ==========\n",
    "        r2_best_model = KNeighborsRegressor(n_neighbors=2) \n",
    "\n",
    "        # Initialization of the combined model\n",
    "        combined_model = combine_methods(ensemble_method, [('trees', r1_best_model), ('knn1', r2_best_model)])\n",
    "\n",
    "        # Fitting on training data\n",
    "        combined_model.fit(X_train, y_train)\n",
    "\n",
    "        # ================================  Results ===================================\n",
    "        # Storing results\n",
    "        y_pred_zones += combined_model.predict(X_test).tolist()\n",
    "        y_true_zones += y_test.tolist()\n",
    "\n",
    "        # Computing R2 metric\n",
    "        accuracy_per_zone = combined_model.score(X_test, y_test)\n",
    "\n",
    "        # Used to have an idea of simulation time (2)\n",
    "        end = time.time() - start\n",
    "\n",
    "        # Displaying information over terminal (2)\n",
    "        print(f\"ZONE ID: {zone_ID} - Best parameters of the tree: {best_parameters[zone_ID-1]} \\\n",
    "              - Accuracy : {accuracy_per_zone} - Time left: {end * (10 - zone_ID)} [s]\")\n",
    "\n",
    "    # Displaying information over terminal (3)\n",
    "    print('End')\n",
    "\n",
    "    return y_pred_zones, y_true_zones, best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212276af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE SEPARATED DATASETS --\n",
    "#\n",
    "# Define the type of dataset\n",
    "dataset_type = \"separated\"\n",
    "\n",
    "# Normalization parameters\n",
    "norm_parameters = [\"standard\", \"column\"]\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Pipeline\n",
    "loader.pipeline(useMeanVariance    = True, var_MV   = [\"U10\", \"V10\", \"U100\", \"V100\"], variance_MV  = True, window_MV = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = True, var_PT   = [\"U10\", \"V10\", \"U100\", \"V100\"], window_ZON = 2,\n",
    "                useNormalize       = True, norm_type = norm_parameters[0], data_type = norm_parameters[1],\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False, SpeedDir_height  = \"both\",\n",
    "                removing           = False)\n",
    "\n",
    "# Finalization\n",
    "loader.finalization(dataset_type = dataset_type)\n",
    "\n",
    "# Creation of the train/test sets\n",
    "X_sep, submit_X_sep, Y_sep, submit_Y_sep = loader.splitTrainTest()\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(X_sep)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING --\n",
    "#\n",
    "# Stores all the results\n",
    "y_pred_ensemble, y_true_ensemble = [], []\n",
    "\n",
    "# Testing possible model combinations\n",
    "for m in [\"RandomForest\", \"ExtraTreesRegressor\"]:\n",
    "    for e in [\"voting\", \"stacking\"]:\n",
    "\n",
    "        # Training and testing\n",
    "        y_pred_zones, y_true_zones, _ = pred_combine_methods(X_sep, Y_sep, first_model_name = m, ensemble_method  = e, \n",
    "                                                            parameters = [{'n_estimators': [5], 'max_depth': [20]}], number_folds  = 2, random_state = 69)\n",
    "        y_pred_ensemble.append(y_pred_zones)\n",
    "        y_true_ensemble.append(y_true_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting final results\n",
    "modelPlotResultsComplex(y_pred_ensemble, y_true_ensemble, [\"RF - Voting\", \"RF - Stacking\", \"ET - Voting\", \"ET - Stacking\"], \n",
    "                        fontsize = 15, save_path = f\"graphs/ensemble/ensemble\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6cfcb77",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model Complex - Training | Testing | Plotting results\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Train and test complex model using the optimal datasets found previously;</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60056f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- POWER OF THE CROWD (CLASS) -- \n",
    "class PowerOfTheCrowd():\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, model_generalized, models_specialized):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - model_generalized  : the model that has been trained on all the data\n",
    "        # \n",
    "        # - models_specialized : a list containing the 10 models that have been trained separately, \n",
    "        #                        they should be ordered by increasing ID number.\n",
    "        #\n",
    "        self.model_gen = model_generalized\n",
    "        self.model_spe = models_specialized\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def score(self, x, y_true, average = \"unique\", return_predict = False):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - x       : the input sample in pandas format\n",
    "        #\n",
    "        # - average : determine if the average is computed between the model i and the generalized (unique) \n",
    "        #             or using all the models (all)\n",
    "        # Security\n",
    "        assert average in [\"unique\", \"all\"], \"Average can either be set to two or all\"\n",
    "        \n",
    "        # ---- Averaging over all predictions ----\n",
    "        if average == \"all\":\n",
    "\n",
    "            # Changing to numpy\n",
    "            x      = x.to_numpy()\n",
    "            y_true = y_true[\"TARGETVAR\"].to_numpy()\n",
    "\n",
    "            # ---- Generalized model predictions  ----\n",
    "            y_gen = self.model_gen.predict(x)\n",
    "\n",
    "            # Stores results\n",
    "            y_pred = np.zeros((11, x.shape[0]))\n",
    "\n",
    "            # Computing each separate models predictions\n",
    "            for i, m in enumerate(self.model_spe):\n",
    "                y_pred[i, :] = m.predict(x)                \n",
    "\n",
    "            # Adding generalized models results\n",
    "            y_pred[10, :] = y_gen[:]\n",
    "\n",
    "            # Computing final score\n",
    "            return np.mean(y_pred, axis = 0), y_true if return_predict else r2_score(y_true, np.mean(y_pred, axis = 0))\n",
    "\n",
    "        # ---- Averaging of corresponding specialized models and generalized model ----\n",
    "        if average == \"unique\":\n",
    "\n",
    "            # Stores all the results\n",
    "            y_pred       = np.empty((0))\n",
    "            y_true_final = np.empty((0))\n",
    "\n",
    "            # Looping over the different zones\n",
    "            for zone_ID in range(1, 11):\n",
    "\n",
    "                # Extracting sub datasets\n",
    "                Xi = x[x[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "                Yi = y_true[\"TARGETVAR\"][y_true[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "\n",
    "                # Security\n",
    "                if len(Xi) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ---- Generalized model predictions  ----\n",
    "                y_gen = self.model_gen.predict(Xi)\n",
    "\n",
    "                # ---- Specialized model predictions  ----\n",
    "                y_spe = self.model_spe[zone_ID - 1].predict(Xi)\n",
    "\n",
    "                # ---- Computing mean of the results ----\n",
    "                y_mean = np.add(y_gen, y_spe)/2\n",
    "\n",
    "                # ---- Concatenation of the results ----\n",
    "                y_pred       = np.concatenate((y_pred, y_mean))\n",
    "                y_true_final = np.concatenate((y_true_final, Yi))\n",
    "\n",
    "            # Computing final score\n",
    "            return y_pred, y_true_final if return_predict else r2_score(y_true_final, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- FUNCTIONS --\n",
    "#\n",
    "# Used to retreive an empty model (to be used by grid search afterward)\n",
    "def getModel(model_name = \"knn\"):\n",
    "    if model_name == \"rt\":\n",
    "        return DecisionTreeRegressor()\n",
    "    if model_name == \"knn\":\n",
    "        return KNeighborsRegressor()\n",
    "    if model_name == \"svr\":\n",
    "        return LinearSVR(dual = False, epsilon = 0.01, loss = 'squared_epsilon_insensitive', random_state = 69)\n",
    "    if model_name == \"rr\":\n",
    "        return Ridge()\n",
    "    if model_name == \"rf\":\n",
    "        return RandomForestRegressor(random_state = 69, n_jobs = 4)\n",
    "    if model_name == \"er\":\n",
    "        return ExtraTreesRegressor(random_state = 69, n_jobs = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8256452",
   "metadata": {},
   "source": [
    "<hr style=\"color:#c6cde1;\"></hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE DATASETS FOR THE COMPLEX MODELS --\n",
    "#\n",
    "# Note : Each pipeline will generate the optimal dataset for the method tested ! \n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X_complex, datasets_X_submit_complex, datasets_Y_complex, datasets_Y_submit_complex = list(), list(), list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Regression tree\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# K-Nearest-Neighbors\n",
    "loader.pipeline(useMeanVariance    = True, window_MV  = 12,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = True, window_ZON = 3,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Linear Support Vector Regression\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = True,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Ridge Regression\n",
    "loader.pipeline(useMeanVariance    = True, window_MV = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# RandomForestRegressor\n",
    "loader.pipeline(useMeanVariance    = True,  window_MV  = 24,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# ExtraTreesRegressor\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = False,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, submit_X, Y, submit_Y = loader.splitTrainTest()\n",
    "datasets_X_complex.append(X), datasets_X_submit_complex.append(submit_X), \n",
    "datasets_Y_complex.append(Y), datasets_Y_submit_complex.append(submit_Y)\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(datasets_X_complex)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebcc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS FOR TRAINING --\n",
    "#\n",
    "# Contains the list of models to test\n",
    "model_complex_list = [\"rt\", \"knn\", \"svr\", \"rr\", \"rf\", \"er\"]\n",
    "\n",
    "# Model (specialiez) parameters to be tested using a gridsearch\n",
    "model_complex_parameters_specialized = [{\"max_depth\"   :[20]                         },\n",
    "                                        {\"n_neighbors\" :[2]                          },\n",
    "                                        {\"C\"           :[0.005]                      },\n",
    "                                        {\"alpha\"       :[7.36]                       },\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]},\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]}\n",
    "                                        ]\n",
    "\n",
    "# Model (generalized) parameters to use\n",
    "model_complex_parameters_generalized = [{\"max_depth\"   :[20]                         },\n",
    "                                        {\"n_neighbors\" :[2]                          },\n",
    "                                        {\"C\"           :[0.005]                      },\n",
    "                                        {\"alpha\"       :[7.36]                       },\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]},\n",
    "                                        {\"max_depth\"   :[60],  \"n_estimators\" : [100]}\n",
    "                                        ]\n",
    "#------------\n",
    "#  Security\n",
    "#------------\n",
    "assert len(model_complex_list) == len(datasets_X_complex),                   f\"Number of datasets = {len(datasets_X_complex)}, Number of models           = {len(model_complex_list)}\"\n",
    "assert len(model_complex_list) == len(model_complex_parameters_specialized), f\"Number of datasets = {len(datasets_X_complex)}, Number of parameters (spe) = {len(model_complex_parameters_specialized)}\"\n",
    "assert len(model_complex_list) == len(model_complex_parameters_generalized), f\"Number of datasets = {len(datasets_X_complex)}, Number of parameters (gen) = {len(model_complex_parameters_generalized)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c59909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING AND TESTING THE COMPLEX MODELS --\n",
    "#\n",
    "# Stores all the complex models created\n",
    "model_complex_trained = []\n",
    "\n",
    "# Stores all the test sets for evaluation afterwards\n",
    "X_test_complex = []\n",
    "Y_test_complex = []\n",
    "\n",
    "# Looping over model, their corresponding datasets and parameters\n",
    "for X_set, Y_set, m, param_spe, param_gen in zip(datasets_X_complex, datasets_Y_complex, model_complex_list, model_complex_parameters_specialized, model_complex_parameters_generalized):\n",
    "\n",
    "    # Displaying information over terminal (1)\n",
    "    section(f\"Model : {m}\")\n",
    "\n",
    "    # Stores all the individual models\n",
    "    models_sep = []\n",
    "\n",
    "    # Stores the train and test set of the generalized model (concatenation of the small one to avoid bias)\n",
    "    X_train_generalized = pd.DataFrame()\n",
    "    Y_train_generalized = pd.DataFrame()\n",
    "    X_test_generalized  = pd.DataFrame()\n",
    "    Y_test_generalized  = pd.DataFrame()\n",
    "\n",
    "    # -------- Separated Models -------- \n",
    "    for zone_ID in range(1, 11):\n",
    "\n",
    "        # Retreiving corresponding data\n",
    "        Xi = copy.deepcopy(X_set[X_set[\"ZONEID\"] == zone_ID])\n",
    "        Yi = copy.deepcopy(Y_set[Y_set[\"ZONEID\"] == zone_ID])\n",
    "\n",
    "        # Creation of training and testing sets\n",
    "        X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(Xi, Yi, test_size = 0.3)\n",
    "\n",
    "        # Adding datasets\n",
    "        X_train_generalized  = pd.concat([X_train_generalized, X_NN_train], axis = 0)\n",
    "        Y_train_generalized  = pd.concat([Y_train_generalized, Y_NN_train], axis = 0)\n",
    "        X_test_generalized   = pd.concat([X_test_generalized,  X_NN_test] , axis = 0)\n",
    "        Y_test_generalized   = pd.concat([Y_test_generalized,  Y_NN_test] , axis = 0)\n",
    "\n",
    "        # Intialization of the model\n",
    "        model = GridSearchCV(getModel(m), param_spe, n_jobs = 4)\n",
    "\n",
    "        # Fitting the data\n",
    "        model.fit(X_NN_train.to_numpy(), Y_NN_train[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "        # Storing the model\n",
    "        models_sep.append(model)\n",
    "\n",
    "        # Computing score\n",
    "        score_spe = model.score(X_NN_test.to_numpy(), Y_NN_test[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "        # Displaying information over terminal (2)\n",
    "        print(f\"Zone {zone_ID}/10 - Best parameter value = {model.best_params_} - Accuracy = {score_spe}\")\n",
    "\n",
    "    # -------- Generalized Model --------\n",
    "    #\n",
    "    # Initialization of the model\n",
    "    model_gen = GridSearchCV(getModel(m), param_gen)\n",
    "\n",
    "    # Fitting the data\n",
    "    model_gen.fit(X_train_generalized.to_numpy(), Y_train_generalized[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "    # Computing score\n",
    "    score_gen = model.score(X_NN_test.to_numpy(), Y_NN_test[\"TARGETVAR\"].to_numpy())\n",
    "\n",
    "    # Displaying information over terminal (2)\n",
    "    print(f\"Zone ALL - Best parameter value = {model_gen.best_params_} - Accuracy = {score_gen}\")\n",
    "\n",
    "    # -------- Complex Model --------\n",
    "    #\n",
    "    # Intialization of the complex model\n",
    "    model_final = PowerOfTheCrowd(model_gen, models_sep)\n",
    "\n",
    "    # Stores all the complex models created\n",
    "    model_complex_trained.append(model_final)\n",
    "    X_test_complex.append(X_test_generalized)\n",
    "    Y_test_complex.append(Y_test_generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EVALUATION OF THE MODEL AND COMPARING RESULTS ---\n",
    "#\n",
    "# Determine if all the separated models are used for prediction or just the corresponding one\n",
    "avg = \"all\"\n",
    "\n",
    "# Stores the predicted and true results\n",
    "y_predict_final = []\n",
    "y_true_final    = []\n",
    "\n",
    "# Testing all the models\n",
    "for x, y, m in zip(X_test_complex, Y_test_complex, model_complex_trained):\n",
    "\n",
    "    # Evaluation of the complex model\n",
    "    y_pred, y_true = m.score(x, y, average = avg, return_predict = True)\n",
    "\n",
    "    # Adding everything\n",
    "    y_predict_final.append(y_pred)\n",
    "    y_true_final.append(y_true)\n",
    "\n",
    "# Definition of the labels\n",
    "labels = [\"RT\", \"KNN\", \"SVR\", \"RR\", \"RF\", \"ER\"]\n",
    "\n",
    "# Plotting final results\n",
    "modelPlotResultsComplex(y_predict_final, y_true_final, labels, fontsize = 15, save_path = f\"graphs/complex/complex_{avg}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c67259b4",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#c6cde1;\">\n",
    "    Model complex - Neural Network\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#c6cde1;\"></hr>\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "    <ul>\n",
    "        <li style=\"margin-bottom:10px\">Create a complex model using a Neural Network</li>\n",
    "    </ul> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdff0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PARAMETERS --\n",
    "# \n",
    "# Number of epochs for the training\n",
    "number_epochs_c = 4\n",
    "\n",
    "# Learning rate\n",
    "lr_c = 0.001\n",
    "\n",
    "# Batch size\n",
    "bs_c = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- GENERATION OF THE DATASETS FOR THE NEURAL NETWORK COMPLEX MODELS --\n",
    "#\n",
    "# Stores all the newly generated datasets\n",
    "datasets_X_complex_NN, datasets_Y_complex_NN = list(), list()\n",
    "\n",
    "# Intialization of the loader\n",
    "loader = dataLoader(dataset_original_X, dataset_original_Y)\n",
    "\n",
    "# Displaying information over terminal (1)\n",
    "print(\"Generating : ...\")\n",
    "\n",
    "# Regression tree\n",
    "loader.pipeline(useMeanVariance    = False,\n",
    "                useZonal           = False,\n",
    "                usePastTime        = False,\n",
    "                useNormalize       = True, norm_type = \"standard\", data_type = \"all\",\n",
    "                useSpeedNorm       = True,\n",
    "                useSpeedDirection  = False,\n",
    "                removing           = False)\n",
    "loader.finalization()\n",
    "X, _, Y, _ = loader.splitTrainTest()\n",
    "\n",
    "# 1 - Adding separate datasets\n",
    "for i in range(1, 11):\n",
    "    datasets_X_complex_NN.append(copy.deepcopy(X[X[\"ZONEID\"] == i]))\n",
    "    datasets_Y_complex_NN.append(copy.deepcopy(Y[Y[\"ZONEID\"] == i]))\n",
    "\n",
    "# Displaying information over terminal (2)\n",
    "print(f\"Number     : {len(datasets_X_complex_NN)}\")\n",
    "print(\"Generating : Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING & TESTING THE COMPLEX MODEL --\n",
    "#\n",
    "# Stores the accuracy of the training and testing\n",
    "nn_accuracy_train = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_accuracy_test  = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_y_pred         = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "nn_y_true         = [[] for i in range(len(datasets_X_complex_NN))]\n",
    "\n",
    "# Stores all the models that have been created\n",
    "model_generalized_NN  = 0\n",
    "models_specialized_NN = []\n",
    "\n",
    "# Stores the test sets\n",
    "X_test_complex  = pd.DataFrame()\n",
    "Y_test_complex  = pd.DataFrame()\n",
    "X_train_complex = pd.DataFrame()\n",
    "Y_train_complex = pd.DataFrame()\n",
    "\n",
    "# Used to compute R2 score\n",
    "rscore = R2Score()\n",
    "\n",
    "# Looping over all the datasets\n",
    "for i, dataset_X, dataset_Y in zip(range(len(datasets_X_complex_NN)), datasets_X_complex_NN, datasets_Y_complex_NN):\n",
    "    \n",
    "    # Creation of train and test sets\n",
    "    X_NN_train, X_NN_test, Y_NN_train, Y_NN_test = train_test_split(dataset_X, dataset_Y, test_size = 0.3)\n",
    "\n",
    "    # Storing the test sets except for the generalized one\n",
    "    if i != len(datasets_X_complex_NN) - 1:\n",
    "        X_test_complex  = pd.concat([X_test_complex, X_NN_test], axis=0)\n",
    "        Y_test_complex  = pd.concat([Y_test_complex, Y_NN_test], axis=0)\n",
    "        X_train_complex = pd.concat([X_train_complex, X_NN_train], axis=0)\n",
    "        Y_train_complex = pd.concat([Y_train_complex, Y_NN_train], axis=0)\n",
    "    else:\n",
    "        X_NN_train = X_train_complex\n",
    "        X_NN_test  = X_test_complex\n",
    "        Y_NN_train = Y_train_complex\n",
    "        Y_NN_test  = Y_test_complex\n",
    "    \n",
    "    # Generation of the datasets\n",
    "    POWER_loader_train   = DataLoader(PowerDataset(X_NN_train, Y_NN_train), batch_size = bs_c)\n",
    "    X_NN_test, Y_NN_test = PowerDataset(X_NN_test,  Y_NN_test).getDatasets()\n",
    "\n",
    "    # Number of inputs in current datasets\n",
    "    nb_inputs =  len(dataset_X.to_numpy()[0])\n",
    "\n",
    "    # Initalization of the network\n",
    "    model_NN = MLP_PowerPrediction(nb_inputs)\n",
    "\n",
    "    # ---- Some stuff you don't need to look into ----\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_NN.parameters(), lr = lr_c)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                               milestones = [int(number_epochs_c/2), int(number_epochs_c * 3/4), int(number_epochs_c * 7/8)], \n",
    "                                               gamma      = 0.1)\n",
    "\n",
    "    # Used to compute training progression bar (1)\n",
    "    size_train = len(X_NN_train)\n",
    "    epoch_time = 0\n",
    "\n",
    "    # Display useful information over terminal (0)\n",
    "    section(f\"Neural Network - Training & Testing : Dataset ({i + 1}/{len(datasets_X_complex_NN)})\")\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(number_epochs_c):\n",
    "\n",
    "        # Used to compute loss\n",
    "        epoch_loss_train  = 0.0\n",
    "        r2_loss_train     = 0.0\n",
    "        epoch_steps_train = 0\n",
    "        epoch_loss_test   = 0.0\n",
    "        epoch_steps_test  = 0\n",
    "\n",
    "        # Display useful information over terminal (1)\n",
    "        print(\"Epoch : \", epoch + 1, \"/\", number_epochs_c)\n",
    "\n",
    "        # Used to compute training progression bar (2)\n",
    "        index = bs_c\n",
    "\n",
    "        # Used to approximate time left for current epoch and in total\n",
    "        start = time.time()\n",
    "\n",
    "        #----------------------\n",
    "        #       Training\n",
    "        #----------------------\n",
    "        # Retreiving a batch of data\n",
    "        for x, y in POWER_loader_train:\n",
    "\n",
    "            # Reseting gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(x)\n",
    "            ytrue = torch.unsqueeze(y, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss = criterion(yhat, ytrue)\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating epoch info ! Would be nice to upgrade it !\n",
    "            epoch_loss_train   += loss.item()\n",
    "            r2_loss_train      += rscore(yhat, ytrue).detach().numpy()\n",
    "            epoch_steps_train  += 1\n",
    "            nb_epoch_left = number_epochs_c - epoch\n",
    "            percentage    = (index/size_train) * 100 if (index/size_train) <= 1 else 100\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, 0, r2_loss_train/epoch_steps_train, epoch_time, nb_epoch_left, percentage)\n",
    "            index += bs\n",
    "\n",
    "        # Updating the scheduler to update learning rate !\n",
    "        scheduler.step()\n",
    "\n",
    "        #----------------------\n",
    "        #       Testing\n",
    "        #----------------------\n",
    "        with torch.no_grad():  \n",
    "\n",
    "            # Computing prediction and storing target\n",
    "            yhat  = model_NN.forward(X_NN_test)\n",
    "            ytrue = torch.unsqueeze(Y_NN_test, dim = 1)\n",
    "\n",
    "            # Computing loss\n",
    "            loss_mse = criterion(yhat, ytrue)\n",
    "            \n",
    "            # Adding preditions for AUC and R2 computation\n",
    "            nn_y_pred[i].append(np.asarray([y[0] for y in yhat.detach().numpy()]))\n",
    "            nn_y_true[i].append(np.asarray([y[0] for y in ytrue.detach().numpy()]))\n",
    "\n",
    "            # Displaying information over terminal (2)\n",
    "            progressBar(epoch_loss_train/epoch_steps_train, loss_mse.item(), rscore(yhat, ytrue), epoch_time, nb_epoch_left, percentage)\n",
    "\n",
    "        # Updating timing\n",
    "        epoch_time    = time.time() - start\n",
    "\n",
    "        # Updating training and test accuracies\n",
    "        nn_accuracy_train[i].append(r2_loss_train/epoch_steps_train)\n",
    "        nn_accuracy_test[i].append(rscore(yhat, ytrue))\n",
    "\n",
    "        # Just to make sure there is no overlap between progress bar and section\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Storing the models\n",
    "        if i == len(datasets_X_complex_NN) - 1:\n",
    "            model_generalized_NN  = model_NN\n",
    "        else:\n",
    "            models_specialized_NN.append(model_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96facbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- POWER OF THE CROWD (Neural Network Version) -- \n",
    "class PowerOfTheCrowdNN():\n",
    "\n",
    "    # Initalization of the model\n",
    "    def __init__(self, model_generalized, models_specialized):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - model_generalized  : the model that has been trained on all the data\n",
    "        # \n",
    "        # - models_specialized : a list containing the 10 models that have been trained separately, \n",
    "        #                        they should be ordered by increasing ID number.\n",
    "        #\n",
    "        self.model_gen = model_generalized\n",
    "        self.model_spe = models_specialized\n",
    "    \n",
    "    # Defining how data will flow through the network\n",
    "    def score(self, x, y_true, average = \"unique\", return_predict = False):\n",
    "        #--------------\n",
    "        # Documentation\n",
    "        #--------------\n",
    "        # - x       : the input sample in pandas format\n",
    "        #\n",
    "        # - average : determine if the average is computed between the model i and the generalized (unique) \n",
    "        #             or using all the models (all)\n",
    "        # Security\n",
    "        assert average in [\"unique\", \"all\"], \"Average can either be set to two or all\"\n",
    "        \n",
    "        # ---- Averaging over all predictions ----\n",
    "        if average == \"all\":\n",
    "\n",
    "            # Changing to numpy\n",
    "            x         = torch.from_numpy(x.to_numpy())\n",
    "            y_true_np = y_true[\"TARGETVAR\"].to_numpy()\n",
    "            y_true    = torch.from_numpy(y_true_np)\n",
    "\n",
    "            # ---- Generalized model predictions  ----\n",
    "            y_gen = np.squeeze(self.model_gen.forward(x).detach().numpy(), axis = 1)    \n",
    "\n",
    "            # Stores results\n",
    "            y_pred = np.zeros((11, x.shape[0]))\n",
    "\n",
    "            # Computing each separate models predictions\n",
    "            for i, m in enumerate(self.model_spe):\n",
    "                y_pred[i, :] = np.squeeze(m.forward(x).detach().numpy(), axis = 1)                \n",
    "\n",
    "            # Adding generalized models results\n",
    "            y_pred[10, :] = y_gen[:]\n",
    "\n",
    "            # Computing final score\n",
    "            return np.mean(y_pred, axis = 0), y_true_np if return_predict else r2_score(y_true_np, np.mean(y_pred, axis = 0))\n",
    "\n",
    "        # ---- Averaging of corresponding specialized models and generalized model ----\n",
    "        if average == \"unique\":\n",
    "\n",
    "            # Stores all the results\n",
    "            y_pred       = np.empty((0))\n",
    "            y_true_final = np.empty((0))\n",
    "\n",
    "            # Looping over the different zones\n",
    "            for zone_ID in range(1, 11):\n",
    "\n",
    "                # Extracting sub datasets\n",
    "                Xi    = torch.from_numpy(x[x[\"ZONEID\"] == zone_ID].to_numpy())\n",
    "                Yi_np = y_true[\"TARGETVAR\"][y_true[\"ZONEID\"] == zone_ID].to_numpy()\n",
    "                Yi    =  torch.from_numpy(Yi_np)\n",
    "\n",
    "                # Security\n",
    "                if len(Xi) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ---- Generalized model predictions  ----\n",
    "                y_gen = np.squeeze(self.model_gen.forward(Xi).detach().numpy(), axis = 1)\n",
    "\n",
    "                # ---- Specialized model predictions  ----\n",
    "                y_spe = np.squeeze(self.model_spe[zone_ID - 1].forward(Xi).detach().numpy(), axis = 1)\n",
    "\n",
    "                # ---- Computing mean of the results ----\n",
    "                y_mean = np.add(y_gen, y_spe)/2\n",
    "\n",
    "                # ---- Concatenation of the results ----\n",
    "                y_pred       = np.concatenate((y_pred, y_mean))\n",
    "                y_true_final = np.concatenate((y_true_final, Yi_np))\n",
    "\n",
    "            # Computing final score\n",
    "            return y_pred, y_true_final if return_predict else r2_score(y_true_final, y_pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- EVALUATION OF THE MODEL AND COMPARING RESULTS --\n",
    "#\n",
    "# Determine if all the separated models are used for prediction or just the corresponding one\n",
    "avg = \"unique\"\n",
    "\n",
    "# Creation of the complex model\n",
    "model_complex_NN = PowerOfTheCrowdNN(model_generalized_NN, models_specialized_NN)\n",
    "\n",
    "# Computing predictions\n",
    "y_pred, y_true = model_complex_NN.score(X_test_complex, Y_test_complex, average = avg, return_predict = True)\n",
    "\n",
    "print(\"R2 Metric:\", r2_score(y_true, y_pred))\n",
    "\n",
    "# Plotting final results\n",
    "modelPlotResultsComplex([y_pred], [y_true], [\"Comple Neural Network\"], fontsize = 15, save_path = f\"graphs/complex_nn/complex_nn_{avg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6970a6b860234838f15385a694e4c719e6911821bb317b2dd9580ae5d017ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
